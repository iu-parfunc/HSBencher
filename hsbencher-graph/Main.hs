{-# LANGUAGE DeriveDataTypeable #-} 
{-# LANGUAGE FlexibleInstances #-}
{-# LANGUAGE RecordWildCards #-}
{-# LANGUAGE NamedFieldPuns #-}
{-# LANGUAGE BangPatterns #-}
{-# LANGUAGE CPP #-}

module Main where

import Control.Exception
-- import Control.Lens
import Control.Monad (unless,when,forM_)
import Data.Char (isNumber)
-- import Data.Colour
-- import Data.Colour.Names
-- import Data.Default.Class

import Control.DeepSeq (force)
import Data.List (elemIndex, intersperse, delete, intercalate, isInfixOf)
import qualified Data.List as L
import Data.List.Split (splitOn)
import qualified Data.Map as M
import Data.Maybe (catMaybes, fromMaybe, listToMaybe)
import Data.String.Utils (strip)
import qualified Data.Set as S
import Data.Typeable
import Data.Version (showVersion)
import Prelude hiding (init) 
import System.Console.GetOpt (getOpt', ArgOrder(Permute), OptDescr(Option), ArgDescr(..), usageInfo)
import System.Environment (getArgs, getProgName)
-- import System.Exit (exitFailure, exitSuccess)
import System.IO (hPutStrLn, stderr, stdin, hGetContents)
import System.IO.Unsafe (unsafePerformIO)
import System.FilePath (replaceExtension)
import System.Process (system)
import System.Exit
import qualified Text.CSV as CSV

-- import Debug.Trace

-- Generated by cabal:
import Paths_hsbencher_graph(version) -- getDataDir

#ifdef USECHART
-- Charting library
import Graphics.Rendering.Chart as C
import Graphics.Rendering.Chart as C 
import qualified Graphics.Rendering.Chart.Backend.Cairo as Cairo
import Graphics.Rendering.Chart.Easy as C
#endif

---------------------------------------------------------------------------
--


{- DEVLOG
  - 11 March 2015: Added Points to GraphMode 

  - 20 Nov 2014: Starting some simplifications and cleanups


-} 

{- Random junk
cabal install HSBencher/hsbencher-tool/ HSBencher/hsbencher-graph/ --bindir=/home/joels/Current/ObsidianWriting/Winter2014/bin/ --force-reinstalls
cat ./text/data/Scan-cse-324974-663.csv | ./bin/grapher -o apa.png --key="ARGS0" --key="ARGS1" -x ARGS2 -y runtime

-} 

-- 
---------------------------------------------------------------------------

-- | CSV data where all rows have the right number of entries.
data ValidatedCSV =
     ValidatedCSV { header :: [CSV.Field]
                  -- TODO: add ixMap that maps each key onto an index or indexing function into a row.
                  -- This is currently redundantly computed in various places.
                  , rows   :: [CSV.Record]
                  }

-- | Groups of rows chunked together by "key"
data KeyedCSV =
     KeyedCSV { keys    :: [ColName]
              , kheader :: [CSV.Field]
              , krows   :: M.Map Key [CSV.Record] }

-- | A combination of fields, e.g. A_B_C, stored as a String.
type Key = String

type ColName = String

-- | For now we only pattern match by string inclusion.  TODO: support regexps?
type Pattern = String

data ErrorCols = ErrDelta  ColName
               | ErrMinMax { errmin:: ColName,  errmax:: ColName }
  deriving (Show,Eq,Read,Ord)

-- The error around a specific point in a given dimension can be
-- either a delta or *bounds*.
data ErrorVal = NoError
              | DeltaVal  Double
              | MinMaxVal Double Double
  deriving (Show,Eq,Read,Ord)
           
-- | Command line flags to the executable.
data Flag = ShowHelp
          | ShowVersion -- TODO: implement this
            
          | OutFile  FilePath

            -- TODO: move this functionality over to a separate executable:
          | DumpFile FilePath -- Dump validated/filtered CSV, in addition to extracted plot.
          | Summary

          | RenderMode GraphMode
          | Title  String
          | XLabel String
          | YLabel String

          -- Log mode
          | YLog  -- logarithmic scale on y-axis
          | XLog  -- logarithmic scale on x-axis 

          -- identify part of a key 
          | Key     { col :: ColName } -- --key="Arg1" --key="Arg2" means Arg1_Arg2 is the name of data series
          | XValues { col :: ColName } -- column containing x-values
          | YValues { col :: ColName } -- column containing y-values

          | YErrValues ErrorCols 

          | FilterContain { col :: ColName, pats :: [Pattern] }
          | FilterEq      { col :: ColName, pats :: [String] }
          | Pad    { col :: ColName, padTo :: Int }
          | Renames FilePath

          -- output resolution  
          | XRes String
          | YRes String

          -- output format
          | OutFormat MyFileFormat

          | GnuPlotTemplate FilePath

          -- Resolving/aggregating duplicates or performing comparisons:
          | Latest  { col :: ColName }
          | Speedup { col :: ColName, contains :: Pattern } 
          | Vs      { col :: ColName, contains :: Pattern }

-- This is getting messy 
            -- Normalize against this column
          | NormaliseKey { col :: ColName }
          | NormaliseVal String 

          | DummyFlag

          --   -- Aux values are not plotted!
          -- | AuxFile String -- a single auxfile that need not have same format as other CSV
          -- | AuxKey  String -- part of key into auxfile
          -- | AuxX    String -- column with aux x value 
          -- | AuxY    String -- column with aux y value 
  deriving (Eq,Ord,Show,Read)


-- This is all a bit unfortunate. 
data MyFileFormat = MySVG | MyPNG | MyPDF | MyPS
                  | MyCSV
                  | MyGPL
                  deriving (Eq, Ord, Show, Read) 

#ifdef USECHART
convToFileFormat :: MyFileFormat -> Cairo.FileFormat
convToFileFormat MySVG = Cairo.SVG
convToFileFormat MyPDF = Cairo.PDF
convToFileFormat MyPNG = Cairo.PNG
convToFileFormat MyPS  = Cairo.PS
convToFileFormat MyCSV = error "Cairo does not do CSV output"
#endif

data GraphMode = Bars | BarClusters | Lines | Points 
               deriving (Eq, Ord, Show, Read )

-- | Type of values stored in a series
data ValueType = Int | Double | String 
               deriving (Eq, Ord, Show, Read )


-- Once things start to work more properly, exception handling should be made proper. 
-- | Exceptions that may occur
data Error
  = FlagsNotValidE String
    deriving (Show, Typeable) 

instance Exception Error 

-- | For now this application is hardcoded to use a particular
-- separator in both rename files and command line arguments.
universalSeparator :: String
universalSeparator = ","

{-# NOINLINE progName #-}
progName :: String
progName = unsafePerformIO getProgName

-- | Parse the comma-separated "COL,VAL" string.
parseFilter :: String -> (ColName,[String])
parseFilter s =
  case splitOn universalSeparator s of
    (l:r1:rest) -> (l,r1:rest)
    _ -> error $ "--filter argument expected at least two strings separated by commas, not: "++s

parseErrCols :: String -> ErrorCols
parseErrCols s =
  case splitOn universalSeparator s of
    [one]   -> ErrDelta one
    [mn,mx] -> ErrMinMax mn mx
    _ -> error $ "--filter argument expected at least two strings separated by commas, not: "++s

parsePad :: String -> (String,Int)
parsePad s =
  case splitOn universalSeparator s of
    [l,r] -> case reads r of
              [(n,"")] -> (l,n)
              _ -> error $ "--filter could not parse this as an integer: "++r
    _ -> error $ "--filter argument expected to be two strings separated by one comma, not: "++s

-- | Command line options.
core_cli_options :: [OptDescr Flag]
core_cli_options = 
     [ Option ['h'] ["help"]    (NoArg ShowHelp)         "Show this help message and exit."
     , Option []    ["version"] (NoArg ShowVersion)      "Show version and exit."
     , Option ['o'] ["out"]  (ReqArg OutFile "FILE")     "Specify result file for main output"

     , Option [] ["cleaned"] (ReqArg DumpFile "FILE")  "Write a cleaned, filtered version of the orig CSV here."      
     , Option [] ["summary"] (NoArg Summary)           "After cleaning, print a summary of each column to stderr."
       
     , Option []    []    (NoArg DummyFlag) "\n Data Handling options"
     , Option []    []    (NoArg DummyFlag) "--------------------------------"

     , Option ['k'] ["key"]    (ReqArg Key     "STR")      "Columns that make part of the key"
     , Option ['x'] ["xvalue"] (ReqArg XValues "STR")      "Column containing x values"
     , Option ['y'] ["yvalue"] (ReqArg YValues "STR")      "Column containing y values"

     -- TODO: especially when using this for CSV->CSV operations.
     -- Allowing multiple dependent variables seems like a good idea.
       
     , Option [] ["error"] (ReqArg (YErrValues . parseErrCols) "STR") $
       "Column containing error for Y dimension.  Either 'COl1,COL2' for\n"++
       "separate lower/upper bounds or just 'COL' for Y-delta."
       
     --  Not ready yet:
     , Option [] ["filtContain"] (ReqArg (uncurry FilterContain . parseFilter) "COL,VAL1,VAL2..") $
       "Filter leaving only rows where COL contains one\n" ++ 
       "of VAL1..VALN as a substring."

     , Option [] ["filtEq"] (ReqArg (uncurry FilterEq . parseFilter) "COL,VAL1,VAL2..") $
       "Filter leaving only rows where COL is exactly equal\n" ++ 
       "to one of VAL1, or exactly equal to VAL2, etc."
       
     -- , Option [] ["sort"] (ReqArg () "STR") $
     --  "Name of a numeric field by which to sort the lines."

     , Option [] ["pad"] (ReqArg (uncurry Pad . parsePad) "COL,N") $
     "Treat COL as a numeric column, and pad numbers to\n"++
     "N characters, preppending leading zeros."        
       
     , Option [] ["renames"] (ReqArg Renames "FILE") $
       "Provide a comma-separated file where each line is an\n" ++
       "OLD,NEW pair indicating renames for data series' names"

       
     , Option []    []    (NoArg DummyFlag) "\n Resolving duplicates and making comparisons"
     , Option []    []    (NoArg DummyFlag) "----------------------------------------------"

     , Option [] ["latest"] (ReqArg Latest "STR") "Grab latest data point according to monotonically increasing column."

 -- TODO: and also move this over to a separate CSV->CSV executable:
     -- , Option [] ["speedup"] (ReqArg (uncurry Speedup . parseFilter) "KEY,VAL") $ ""
     -- , Option [] ["vs"] (ReqArg (uncurry Vs . parseFilter) "KEY,VAL") $ ""       
       
     , Option []    []    (NoArg DummyFlag) "\n Presentation options"
     , Option []    []    (NoArg DummyFlag) "--------------------------------"

-- Not finished yet, don't mention [2015.02.22]:       
--     , Option []    ["bars"] (NoArg (RenderMode Bars))       "Plot data as bars"
--     , Option []    ["barclusters"] (NoArg (RenderMode BarClusters)) "Plot data as bar clusters"

     , Option []    ["points"] (NoArg (RenderMode Points))   "Plot data as points" 
     , Option []    ["lines"] (NoArg (RenderMode Lines))     "Plot data as lines"
       
     , Option []    ["title"] (ReqArg Title "String")        "Plot title" 
     , Option []    ["xlabel"] (ReqArg XLabel "String")      "X-axis label"
     , Option []    ["ylabel"] (ReqArg YLabel "String")      "Y-axis label"
       
     -- Logarithmic scales
     , Option []     ["ylog"] (NoArg YLog)                "Logarithmic scale on y-axis"
     , Option []     ["xlog"] (NoArg XLog)                "Logarithmix scale on x-axis" 

     , Option []    ["CSV"]    (NoArg (OutFormat MyCSV)) "Output raw CSV data to file selected by --out"

#ifdef USECHART
     , Option []    []    (NoArg DummyFlag) "\n Haskell Chart specific options"
     , Option []    []    (NoArg DummyFlag) "--------------------------------"
      
     -- plot configuration 
     , Option []    ["xres"]   (ReqArg XRes "String")    "X-resolution of output graphics"
     , Option []    ["yres"]   (ReqArg XRes "String")    "Y-resolution of output graphics"
     , Option []    ["SVG"]    (NoArg (OutFormat MySVG)) "Output in SVG format"
     , Option []    ["PDF"]    (NoArg (OutFormat MyPDF)) "Output in PDF format"
     , Option []    ["PS"]     (NoArg (OutFormat MyPS))  "Output in PS format"
     , Option []    ["PNG"]    (NoArg (OutFormat MyPNG)) "Output in PNG format"

#else
     , Option []    []    (NoArg DummyFlag) "\n Haskell Chart support not compiled in!  No options."
     , Option []    []    (NoArg DummyFlag) "-----------------------------------------------------"
#endif
      
     , Option []    []    (NoArg DummyFlag) "\n Normalisation:"
     , Option []    []    (NoArg DummyFlag) "----------------"

       
     , Option []    ["normalise"] (ReqArg NormaliseKey "String") "What value to normalise against" 
       
     , Option []    []    (NoArg DummyFlag) "\n GNUPlot Options:"
     , Option []    []    (NoArg DummyFlag) "------------------"

     , Option []    ["GPL"] (NoArg (OutFormat MyGPL))  "Output a .gpl plot script + CSV data."
     , Option []    ["template"] (ReqArg GnuPlotTemplate "FILE") "Prepend FILE to generated gnuplot scripts."       

     ]

-- | Multiple lines of usage info help docs.
fullUsageInfo :: String
fullUsageInfo = usageInfo docs core_cli_options
 where 
  docs = "USAGE: "++progName++" <flags> ... <inputCSVfiles> ...\n"++
         "Version: "++showVersion version++"\n"++
         
         "\nA utility for plotting datasets retrieved from HSBencher.\n"++
         "\nReads CSV data from stdin if no input files are given.\n\n"++

         "Basic usage guide:\n"++
         " \n"++
         "\n"++
         "Currently incomplete functionality: :\n"++
         " * bar charts are not supported in gnuplot output\n"++
         
         "\nCommand line flags: \n"
--   ++ generalUsageStr

---------------------------------------------------------------------------
-- Data representations
---------------------------------------------------------------------------
data SeriesData = IntData Int 
                | NumData Double
                | StringData String
                  deriving (Show, Eq, Ord, Read)

convertToString :: SeriesData -> String
convertToString (IntData x) = (show x)
convertToString (NumData x) = (show x)
convertToString (StringData a) = a

isNum :: SeriesData -> Bool
isNum (NumData _) = True
isNum _ = False

seriesType :: SeriesData -> ValueType
seriesType (IntData _) = Int
seriesType (NumData _) = Double
seriesType (StringData _) = String 

class FromData a where
  fromData :: SeriesData -> a

instance FromData Double where
  fromData (NumData a) = a
  fromData (IntData n) = fromIntegral n -- RRN: TEMP: sanity check this.  Allow Int to "subtype" as double.
  fromData e = error $ "FromData Double, could not parse as Double: "++show e

instance FromData Int where
  fromData (IntData a) = a
  fromData e = error$ "FromData Int, could not parse: "++show e

instance FromData String where
  fromData (StringData a) = a
  fromData e = error "FromData String, could not parse: "++show e 

---------------------------------------------------------------------------
-- Data series
---------------------------------------------------------------------------

-- | These correspond to lines in the plot: named progressions of (x,y) pairs.
type DataSeries = M.Map String [Point] 
data Point = Point { x::SeriesData, y::SeriesData, err::ErrorVal }
  deriving (Eq,Show,Ord,Read)

insertVal :: DataSeries -> String -> Point -> DataSeries
insertVal m key val =
  case M.lookup key m of
    Nothing -> M.insert key [val] m 
    Just vals -> M.insert key (val:vals) m


---------------------------------------------------------------------------
-- Plot configuration
---------------------------------------------------------------------------
data PlotConfig = PlotConfig { plotOutFile    :: FilePath
                             , plotOutFormat  :: MyFileFormat 
                             , plotResolution :: (Int,Int)                                
                             , plotTitle      :: String
                             , plotXLabel     :: String
                             , plotYLabel     :: String
                             , plotYLog       :: Bool
                             , plotXLog       :: Bool
                             , plotErrorCols  :: Maybe ErrorCols
                             , gnuPlotTemplate :: Maybe FilePath
                             , plotMode       :: GraphMode
                             }
                  deriving (Show, Eq, Read, Ord)

chatter :: String -> IO ()
chatter str = hPutStrLn stderr $ " [hsbencher-graph] " ++str

---------------------------------------------------------------------------
-- MAIN
---------------------------------------------------------------------------
main :: IO ()
main = do
  args <- getArgs

  let (options, inFiles, unrec,errs) = getOpt' Permute core_cli_options args

      normaliseSpecified = (not . null) [ () | NormaliseKey _ <- options] 
  
      xRes = head $ [readInt x | XRes x <- options] ++ [800]
      yRes = head $ [readInt y | YRes y <- options] ++ [600]
  
      plotTitle = head $ [t | Title t <- options] ++ ["NO_TITLE"]
      xLabel    = head $ [l | XLabel l <- options] ++
                         [c | XValues c <- options] ++
                         ["X-Axis"] -- Last resort, default
      yLabel    = head $ [l | YLabel l <- options] ++
                         [c | YValues c <- options] ++
                         ["Y-Axis"]

      -- Should any axis be log scale
      y_logscale = (not . null) [() | YLog <- options]
      x_logscale = (not . null) [() | XLog <- options]
  
  outFormat <- case [ format | OutFormat format <- options] of 
                 []  -> do chatter$ "Warning: no output format selected.  Defaulting to CSV output."
                           return MyCSV 
                 [x] -> return x
                 ls  -> error$ "multiple output formats not yet supported: "++show ls  

  unless (null errs) $ do
    chatter$ "Errors parsing command line option(s):"
    mapM_ (putStr . ("   "++)) errs       
    exitFailure
  unless (null unrec) $ do
    chatter$ "Unrecognized command line option(s):"
    mapM_ (putStr . ("   "++)) unrec  
    exitFailure

  when (ShowHelp `elem` options) $ do 
    putStrLn fullUsageInfo
    exitSuccess
  when (ShowVersion `elem` options) $ do
    putStrLn $ progName ++ ": version "++showVersion version
    exitSuccess

  --------------------------------------------------
  -- Get target
  let outFile = fromMaybe (error  "Error: an output file has to be specified") $ 
                listToMaybe [file | OutFile file <- reverse options]

  --------------------------------------------------
  -- Get keys
  let hasKey  = (not . null) [ () | Key _ <- options]  
      key =
        case hasKey of
          False -> error "No key specified" 
          True  -> [ q | Key q <- options] 

  let hasX    = (not . null) [ () | XValues _ <- options]  
      hasY    = (not . null) [ () | YValues _ <- options]  

      plotErrorCols = listToMaybe [ e | YErrValues e <- options ]
      xyerr =
        case hasX && hasY of
          False -> error "Both -x and -y arguments are needed"
          True  -> (head [x | XValues x <- options],
                    head [y | YValues y <- options],
                    plotErrorCols )

      gnuPlotTemplate = head $ [ Just f | GnuPlotTemplate f <- options] ++ [Nothing]

      renderModes = [ x | RenderMode x <- options]

  renderMode <- 
    case renderModes of
      [] -> do
        chatter $ "No mode (--lines, --points) specified. Defaulting to draw lines"
        return Lines
      [x] -> return x 
      (x:_) -> do
        chatter $ "More than one mode specified. Using " ++ show x
        return x 
  
  --------------------------------------------------
  -- All the collected parameters for the plotting. 
  let plotConf = PlotConfig outFile
                            outFormat
                            (xRes,yRes)
                            plotTitle
                            xLabel
                            yLabel
                            y_logscale
                            x_logscale
                            plotErrorCols
                            gnuPlotTemplate
                            renderMode
  
  --------------------------------------------------
  -- Acquire data:

  -- Input files must have same CSV layout
  -- and same format as any CSV arriving in pipe:
  rawdat <- case inFiles of
             []    -> do str <- hGetContents stdin
                         chatter$ "Reading CSV from stdin... "
                         return $ CSV.parseCSV "stdin" str
             [one] -> do chatter$ "Reading CSV from input file: "++one
                         CSV.parseCSVFromFile one
             _     -> error$ "doesn't currently support reading from multiple files: "++show inFiles

  dat0 <- case rawdat of
            Left err -> error $ "Error parsing CSV data: \n"++show err
            Right d  -> do chatter$ "Successfully parsed CSV input dataset."
                           return d
  let dat1 = validateCSV dat0
      dat2 = doFilters options dat1
      dat3 = doPadding [ (c,n) | Pad c n <- options ] dat2
      dat4 = case [ c | Latest c <- options] of
               []  -> dat3
               [c] -> -- Here we must not collapse variation in the X axis:
                      takeLatest (fst3 xyerr : key) c dat3
               ls  -> error $ "Error: More than one --latest provided: "++show ls
  chatter $ "After validation, read total rows: " ++ show (length (rows dat1))
  _ <- evaluate (force (rows dat4))  -- Flush out error messages.
  chatter $ "Data filtering completed successfully, rows remaining: " ++ show (length (rows dat4))
  forM_ [ f | DumpFile f <- options ] $ \fl -> do
    chatter $ "Writing cleaned/filtered copy of CSV data to: "++fl
    writeFile fl (CSV.printCSV (fromValidated dat4))

  unless (null [ () | Summary <- options ]) $ printSummary dat4

  (csv,aux) <- extractData key xyerr dat4
  chatter $ "Data series extracted, number of lines: " ++ show (M.size csv)

  chatter$ "Here is a sample of the CSV before renaming and normalization:\n" ++
    unlines [ "    "++take 100 (show l)++"..." | l <- (take 5 (M.toList csv))] ++ "    ...."
  chatter$ "Also, a sample of 'aux': "++ take 500 (show aux) 

  --------------------------------------------------
  -- Data preprocessing / munging:

  renameTable <- fmap (concatMap lines) $
                 mapM readFile [f | Renames f <- options] 
  let series1 :: [(String,[Point])]
      series1 = M.assocs csv
  
      series2 = map unifyTypes series1
      series_type = typecheck series2 

      -- normalise values against this datapoint
      normKey = head [nom | NormaliseKey nom <- options]   
      base = getBaseVal normKey csv aux 
            
      plot_series0 = if normaliseSpecified       
                     then normalise base series2
                     else series2
      renamer = buildRenamer renameTable
      plot_series :: [(String, [Point])]
      plot_series = [ (renamer nm,dat) | (nm,dat) <- plot_series0 ]
  
  chatter$ "Inferred types for X/Y axes: "++show series_type  
  
  --------------------------------------------------
  -- do it      
  case (outFormat, series_type) of
    (_,Nothing) -> error $ "Series failed to typecheck"
    (MyCSV, _)  -> writeCSV plotConf plot_series
    (MyGPL, _)  -> do chatter "Writing out both CSV file and a GnuPlot script to plot it."
                      writeCSV     plotConf plot_series
                      writeGnuplot plotConf plot_series 
#ifdef USECHART    
    (_,Just (Int,Int))       -> plotIntInt plotConf plot_series
    (_,Just (Int,Double))    -> plotIntDouble plotConf plot_series
    (_,Just (Double,Double)) -> plotDoubleDouble plotConf plot_series
#endif    
    (_,Just (_,_)) -> error $ "no support for plotting of this series type: "++show series_type++
                              ", with this output format: "++show outFormat

  
---------------------------------------------------------------------------
-- Plotting


-- | Don't produce an actual chart, rather write out the data as CSV.
writeCSV :: PlotConfig -> [(String, [Point])] -> IO ()
-- Assumes a shared and sensible X axis for all data series.
writeCSV PlotConfig{..} series = do
  -- ASSUMPTION: we assume a sensible Ord instance for
  -- SeriesData... that makes possible unfair assumptions about
  -- "deriving":
  let allKeys = map convertToString $
                S.toAscList $ S.fromList $ concatMap ((map x) . snd) series
      -- Format:  all data columns before all error columns:
      header = [plotXLabel] ++ yCols ++ yErrs
      yCols  = map fst series
      yErrs  = case plotErrorCols of
                 Nothing -> []
                 Just (ErrDelta _)    -> map (++"_Err")     yCols
                 Just (ErrMinMax _ _) -> map (++"_ErrLow")  yCols ++
                                         map (++"_ErrHigh") yCols 

      -- nested map from key -> x -> (y,yErr)
      alldata = M.map (\prs -> M.fromList
                        [ (convertToString x, (convertToString y, err)) | Point{x,y,err} <- prs ] ) $ 
                M.fromList series
                
      rows = [ key : buildRow key | key <- allKeys ]

      buildRow key =
        let gogo f = [ case M.lookup key seriesMap of
                        Nothing -> "" -- TODO, make configurable.  Missing data for this X value in this line.
                        Just dat -> f dat
                     | (seriesName, _) <- series 
                     , let seriesMap = alldata M.! seriesName ]
        in 
        -- Row has Y values then Y errors:
        gogo fst ++ 
        case plotErrorCols of
          Nothing              -> []
          Just (ErrDelta _)    -> gogo (\ (_,DeltaVal d) -> show d)
          Just (ErrMinMax _ _) -> gogo (\ (_,MinMaxVal mn _) -> show mn) ++
                                  gogo (\ (_,MinMaxVal _ mx) -> show mx)
      
      csvResult = CSV.printCSV (header:rows)
  chatter $ "Writing out CSV for "++show (length series)++" data series (lines) named: "++unwords (tail header) 
  writeFile plotOutFile csvResult
  chatter $ "Succesfully wrote file "++show plotOutFile

  
writeGnuplot :: Show a => PlotConfig -> [(a, t)] -> IO ()
writeGnuplot PlotConfig{..} series = do
  let gplfile = replaceExtension plotOutFile "gpl"
  let numSeries = length series      
  let mkPlotClauses seriesName ind =
        case plotMode of
          Lines -> 
            let basicLine sty = show plotOutFile++" using 1:"++show ind ++
                                " title "++show seriesName++" w "++sty++" ls "++show(ind-1) 
                errorStyle = " notitle with yerrorbars ls 99 " -- ++show(ind-1)
            in 
             case plotErrorCols of
               Nothing -> [ basicLine "linespoints" ]
               Just (ErrDelta _) ->
                 [ basicLine "lines" 
                 , show plotOutFile++" using 1:"++show ind++":"++
                   show (ind + numSeries) ++ errorStyle              
                 ]
               Just (ErrMinMax _ _) ->
                 [ basicLine "lines" 
                 , show plotOutFile++" using 1:"++show ind++":"++
                   show (ind + numSeries)++":"++show (ind + 2*numSeries)++
                   errorStyle
                 ]
          Points -> [show plotOutFile++" using 1:"++show ind ++
                     " title "++show seriesName++" w points ps "++show(ind-1)]
      
      -- usingClause ind =
      --   case plotErrorCols of 
      --     Nothing -> "using 1:"++show ind
      --     Just (ErrDelta _)    -> "using 1:"++show ind++":"++ 
      --                             show (ind + numSeries) ++ " with yerrorbars"
      --     Just (ErrMinMax _ _) -> "using 1:"++show ind++":"++
      --                             show (ind +   numSeries)++":"++
      --                             show (ind + 2*numSeries) ++ " with yerrorbars"
          
  chatter $ "Writing out Gnuplot script as well as CSV: "++gplfile
  let gplLines = [ "\n# Begin "++progName++" generated script:"
                 , "set xlabel "++ show plotXLabel
                 , "set ylabel "++ show plotYLabel
                 , "set output "++ show (replaceExtension plotOutFile "pdf")
                 , "# And because we're plotting CSV data:"
                 , "set datafile separator \",\""
                 , "plot "++ concat (intersperse ", \\\n     "
                   -- Line them up carefully by position:
                   (concat [ mkPlotClauses seriesName ind
                           | ((seriesName, _),ind) <- zip series [2::Int ..] ]))
                 ]
-- TODO, make this into a library and look up the template file in ~/.cabal/share (from the Paths_ module)
--      defaultTemplate = "template.gpl"
      defaultTemplate = error "ERROR: For now you must provide GnuPlot template with --template"
      template = fromMaybe defaultTemplate gnuPlotTemplate 
  -- FIXME: assumes the template is in the current directory.  Use a more principled way:
  prelude <- fmap lines $ readFile template
  writeFile gplfile (unlines (prelude ++ gplLines))
  chatter $ "Succesfully wrote file "++show gplfile

  let cmd = "gnuplot "++gplfile
  chatter $ "Attempting to use gnuplot command to build the plot:"++show cmd
  cde <- system cmd
  case cde of
    ExitSuccess   -> chatter "Gnuplot returned succesfully."
    ExitFailure c -> chatter$ "WARNING: Gnuplot process returned error code: "++show c
  return ()
  

#ifdef USECHART
plotIntInt :: PlotConfig -> [(String, [(SeriesData, SeriesData)])] -> IO ()
plotIntInt conf series = error "hsbencher-graph: plotIntInt not implemented!"

plotIntDouble :: PlotConfig -> [(String, [(SeriesData, SeriesData)])] -> IO ()
plotIntDouble conf  series = do 
  let fopts = Cairo.FileOptions (plotResolution conf)
                                (convToFileFormat (plotOutFormat conf))
  Cairo.toFile fopts (plotOutFile conf) $ do

    -- 13 colors
    setColors $ map opaque
              [blue, green, orange, red
              ,brown, black, darkblue, darkgray
              ,darkgreen, darkorange, darkred, yellow, violet]
    
    layout_title .= plotTitle conf
    layout_background .= solidFillStyle (opaque white)
    layout_foreground .= opaque black
    layout_left_axis_visibility . axis_show_ticks .= True
    layout_title_style . font_size .= 24

    if (plotYLog conf)
      then layout_y_axis . laxis_generate .= autoScaledLogAxis (LogAxisParams show) 
      else return () 


    -- Not Possible in IntDouble plot
    --if (plotXLog conf)
    --   then layout_x_axis . laxis_generate .= autoScaledLogAxis (LogAxisParams show)
    --   else return () 

    -- hint ? 
    --layout_x_axis . laxis_generate .= autoIndexAxis (map fst values)  
            
    
    
    mapM_ plotIt series 
  
  where
    plotIt (name,xys) = do
      color <- takeColor
      shape <- takeShape

      let (xs,ys) = unzip xys
          xsi     = map fromData xs :: [Int]
          ysd     = map fromData ys :: [Double]
          sorted  = (sortBy (\(x,_) (x',_) -> x `compare` x')  $ zip xsi ysd)
          
      plot $ myline color name [sorted]
      plot $ mypoints color shape name sorted
        
    myline :: AlphaColour Double -> String -> [[(x,y)]]  -> EC l (PlotLines x y)
    myline color title values = liftEC $ do
      plot_lines_title .= title
      plot_lines_values .= values
      plot_lines_style . line_color .= color
      plot_lines_style . line_width .= 1


    mypoints :: AlphaColour Double -> PointShape -> String -> [(x,y)] -> EC l (PlotPoints x y)
    mypoints color shape name values = liftEC $ do
      plot_points_values .= values
      plot_points_title .= name
      plot_points_style . point_color .= transparent 
      plot_points_style . point_shape .= shape
      plot_points_style . point_border_width .= 1
      plot_points_style . point_border_color .= color
      plot_points_style . point_radius .= 2

plotDoubleDouble :: PlotConfig -> [(String, [(SeriesData, SeriesData)])] -> IO ()
plotDoubleDouble = error "hsbencher-graph: plotDoubleDouble not implemented!!"

#endif

---------------------------------------------------------------------------
-- Types in the data 

unifyTypes :: (String,[Point]) -> (String,[Point])
unifyTypes (name,series) =
  let (xs,ys,errs) = (map x series, map y series, map err series)
      xs' = unify xs
      ys' = unify ys
  in (name, zipWith3 Point xs' ys' errs)
  where
    isString :: SeriesData -> Bool
    isString (StringData _) = True
    isString _ = False

    isInt :: SeriesData -> Bool
    isInt (IntData _) = True
    isInt _ = False 
    
    unify xs =
      case (any isString xs, any isInt xs, any isNum xs) of
        (True, _, _)   -> map (StringData . convertToString) xs
        (False,_,True) -> map convertToNum xs
        (False,True,False) -> xs
    convertToNum (IntData x) = NumData (fromIntegral x)
    convertToNum (NumData x) = NumData x
    convertToNum (StringData str) = error $ "Attempting to convert string " ++ str ++ " to Num" 

typecheck :: [(String,[Point])] -> Maybe (ValueType, ValueType) 
typecheck dat =
  let series = concatMap snd dat
      (xs,ys) = (map x series, map y series)
  in
   case length xs >= 1 && length ys >= 1 of 
     True ->
       let x = seriesType $ head xs
           y = seriesType $ head ys
           _xb = all (==x) $ map seriesType xs
           _yb = all (==y) $ map seriesType ys
       in Just (x,y)
     False -> Nothing 

---------------------------------------------------------------------------

-- | Extract the data we care about from in-memory CSV data:
--      
-- Note: This is in the IO monad only to produce chatter.
extractData :: [ColName] -> (ColName,ColName,Maybe ErrorCols)
            -> ValidatedCSV -> IO (DataSeries,DataSeries)
extractData keys (xcol,ycol,errcols) (ValidatedCSV header rest) = 
  case (length keyIxs) == (length keys) of
    False -> error $ "Keys "++ show keys++" were not all found in schema: "++show csvhdr
    True -> do
      (m',aux') <- loop (xcolIx,ycolIx) (M.empty,M.empty) rest
      return (m',aux')
  where
    csvhdr = map strip header
    keyIxs = catMaybes $ zipWith elemIndex keys (replicate (length keys) csvhdr)
    xcolIx = getIx xcol
    ycolIx = getIx ycol

    getIx col =
       case elemIndex col csvhdr of
          Just ix -> ix
          Nothing -> error $ show ycol ++ " is not present in csv."        

    loop _ (m,aux) [] = return (m,aux)
    loop xy (m,aux) (row:restRows)= do
      case row of
        -- In the odd event that an empty line occurs:
        []  -> loop xy (m,aux) restRows
        -- A real string, lets see if it contains anything useful:
        _ -> do
          -- split out the csv fields 
          let csv = map strip row
              -- Construct a key
              key = combineFields keyIxs csv      

              -- Find x,y pairs
              (xStr,yStr)  = collectXY xy csv
          -- empty string at key position. 
          -- May be of importance! 
          case (xStr,yStr) of
            ("","") -> do chatter$ "has no x/y values: " ++ show key ++ " discarding."
                          loop  xy (m,aux) restRows
            ("",a)  -> do chatter$ "has no x value: " ++ show key ++ " Goes into aux data."
                          let aux' = insertVal aux key (Point{ x= StringData "NO_X_VALUE"
                                                             , y= toSeriesData a
                                                             , err=NoError })
                          loop  xy (m,aux') restRows
            (_a,"") -> do chatter$ "has no y value: " ++ show key ++ " discarding."
                          loop  xy (m,aux) restRows
            (x,y)   -> let e = case errcols of
                                 Nothing -> NoError
                                 Just (ErrDelta nm) -> DeltaVal $ readDbl $ collectVal (getIx nm) csv
                                 Just (ErrMinMax mn mx) ->
                                   MinMaxVal (readDbl$ collectVal (getIx mn) csv)
                                             (readDbl$ collectVal (getIx mx) csv)
                           m' = insertVal m key (Point { x= toSeriesData x
                                                       , y= toSeriesData y
                                                       , err=e
                                                       })
                       in  loop  xy (m',aux) restRows
        
    
    collectXY (x,y) csv =  ( collectVal x csv
                           , collectVal y csv)
    -- FIXME: I believe using maps is a lot cleaner 
    collectVal ix csv =
      -- trace ("Dereferencing !!2: "++show(csv,ix)) $
      csv !! ix 

    toSeriesData x =
      case recogValueType x of
        Int -> IntData (read x) 
        Double -> NumData (read x) 
        String -> StringData x        

---------------------------------------------------------------------------
-- Recognize data


-- The rules.
-- The string contains only numerals -> Int
-- The string contains only numerals and exactly one . -> Double
-- the string contains exactly one . and an e -> Double 
-- The string contains any non-number char -> String

-- there is an ordering to the rules.
-- # 1 If any element of the
--     input contains something that implies String. They are all interpreted as Strings
-- # 2 If not #1 and any element contains . or . and e All values are doubles
-- # 3 If not #1 and #2 treat as Int

-- May be useless. just treat all values as "Double" 

-- | Figure out what type of value is stored in this data series.     
recogValueType :: String -> ValueType
recogValueType str =
  case (isString str, isInt str, isDouble str) of
    (True,_,_)           -> String
    (False,True, False)  -> Int
    (False,_, True)      -> Double
    (_, _, _)            -> String
  where 
    isInt s = all isNumber s
    -- Not a very proper check. 
    isDouble s = ((all isNumber $ delete '.' s)
                    || (all isNumber $ delete '.' $ delete 'e' s)
                    || (all isNumber $ delete '.' $ delete 'e' $ delete '-' s))
                   && '.' `elem` s
    isString s = not (isInt s) && not (isDouble s)




---------------------------------------------------------------------------
-- get a value to normalise against 
---------------------------------------------------------------------------

getBaseVal :: Ord k => k -> M.Map k a -> M.Map k a -> a
getBaseVal normKey csv aux =
  case (M.lookup normKey csv, M.lookup normKey aux) of
    (Nothing, Nothing) -> error "Value to normalise against not found"
    (Just v,_) -> v
    (_,Just v) -> v
      


normalise :: [Point] -> [(String,[Point])] -> [(String,[Point])]
normalise []   _  = error "No Value to normalise against"
normalise _ [] = []
normalise base0 ((nom,series):rest0) 
  = (nom,normalise' base0 series):normalise base0 rest0
  where
    normalise' ::  [Point] -> [Point] ->  [Point] 
    normalise' _ [] = []
    normalise' base (pt:rest) =
      doIt base pt : normalise' base rest
    doIt ((Point{y=NumData y}):_) (Point {x=sx, y= NumData sy, err}) =
      Point {x=sx, y=NumData ((sy-y)/y), err }
  

replace :: Eq a => [a] -> [a] -> [a] -> [a]
replace old new = intercalate new . splitOn old

buildRenamer :: [String] -> String -> String
buildRenamer [] = id
buildRenamer (ln:rest) =
  case (splitOn "," ln) of
    [lhs,rhs] -> \str -> buildRenamer rest
                           (replace lhs rhs str)
    _ -> error ("Bad line in rename table: "++ ln)

fromValidated :: ValidatedCSV -> CSV.CSV
fromValidated ValidatedCSV{header,rows} = header : rows  

-- | Take pre-validated CSV and apply filters to CSV data.
doFilters :: [Flag] -> ValidatedCSV -> ValidatedCSV
doFilters [] dat = dat
doFilters (FilterEq col vals : rest) (ValidatedCSV header csv) =
   doFilters rest $ ValidatedCSV header $
     filter ((\x -> any (==x) vals) . mkPrj header col) csv
doFilters (FilterContain col vals : rest) (ValidatedCSV header csv) =
   doFilters rest $ ValidatedCSV header $ 
     filter ((\x -> any (`isInfixOf` x) vals) . mkPrj header col) csv   

-- | Everything else we ignore:
doFilters (_ : rest) dat = doFilters rest dat

mkPrj :: (Show b, Eq b) => [b] -> b -> [a] -> a
mkPrj header col = 
  case elemIndex col header of
    Just ix -> \row ->
      -- trace ("Dereferencing: !!0"++show(row,ix)) $ 
      row !! ix
    Nothing -> error $ show col ++ " is not present in csv." 


doPadding :: [(String,Int)] -> ValidatedCSV -> ValidatedCSV
doPadding ls (ValidatedCSV header csv) =
   ValidatedCSV header $ loop ls csv
  where
   loop [] rows = rows
   loop ((col,pad):rest) rows = map (mkPadder col pad) $
                                loop rest rows
   mkPadder :: ColName -> Int -> CSV.Record -> CSV.Record
   mkPadder col padto =
     let padit s = 
           -- Make sure it is a number we are padding
          case reads s of
             [(n,"")] -> let s' = show (n::Integer)
                         in replicate (padto - length s') '0' ++ s'
             _ -> error $ "attempting to --pad something not an integer: "++s
         
           in 
     case elemIndex col header of
       Just ix -> \row ->         
         let row' = take (ix) row ++ [padit (row !! ix)] ++ drop (ix+1) row
         in -- trace ("PADDING ROW "++col++" at index "++ show ix++": "++show row')
            row'
       Nothing -> error $ show col ++ " is not present in csv." 

-- | Resolve groups of rows that share the same key
takeLatest :: [ColName] -> ColName -> ValidatedCSV -> ValidatedCSV
takeLatest keys col dat =
  let keyed = toKeyedGroups keys dat
      hdr   = header dat
      mp'   = M.map (\ls -> reverse $ rows $
                            sortCSVBy col compareStrDoubles (ValidatedCSV hdr ls))
                    (krows keyed)
      remaining = L.map head (M.elems mp')
  in ValidatedCSV hdr remaining

-- | Comparison on Strings that are actually valid Doubles.
compareStrDoubles :: String -> String -> Ordering
compareStrDoubles a b =
  case (reads a,reads b) of
    ((n,_):_,(m,_):_) -> compare (n::Double) m
    _ -> error $ "compareStrDoubles: expected both of these to parse as Double: "++ show (a,b)

-- | Sort the rows by a certain column.  
sortCSVBy :: ColName -> (String -> String -> Ordering) -> ValidatedCSV -> ValidatedCSV
sortCSVBy col fn ValidatedCSV{header,rows} = ValidatedCSV header rows'
-- This does seem to get into needless reimplementation of DB functionality...
 where
  rows' = L.sortBy fn' rows
  fn' a b = fn (prj a) (prj b)
  prj = mkPrj header col

toKeyedGroups :: [ColName] -> ValidatedCSV -> KeyedCSV
toKeyedGroups keys ValidatedCSV{header,rows} =
  case (length keyIxs) == (length keys) of
    False -> error $ "Keys "++ show keys++" were not all found in schema: "++show header
    True -> KeyedCSV keys header (loop M.empty rows)
 where
  keyIxs = catMaybes $ zipWith elemIndex keys (replicate (length keys) header)
  loop !mp [] = mp
  loop !mp (row:rest) =
    let mp' = M.insertWith' (++) (combineFields keyIxs row) [row] mp in
    loop mp' rest
    

-- Project multiple rows and put them together in a human readable way:
combineFields :: [Int] -> [CSV.Field] -> String
combineFields ixs row = concat $ intersperse "_" $ filter (/="") $
                        map (\i -> row !! i) ixs

-- | Collapse keyed groups back down to a flat list of rows, in no
-- particular order.
fromKeyedGroups :: KeyedCSV -> ValidatedCSV 
fromKeyedGroups KeyedCSV{kheader,krows} = 
  ValidatedCSV kheader (M.fold (++) [] krows)

-- | Make sure that each row has the right number of columns ad discard blank lines.
--   Remove any whitespace around header column names.
-- 
--   If the ValidatedCSV constructor is stripped off and this is
--   reapplied, then this function must be idempotent.
validateCSV :: CSV.CSV -> ValidatedCSV
validateCSV [] = error "validateCSV: empty CSV data (no header row)"
validateCSV (header:csv) = ValidatedCSV (map strip header) (loop (2::Int) csv)
  where
   numCols = length header -- TODO: could validate that column names look
                           -- right, i.e. probably shouldn't be numbers!
   loop _ [] = []
   loop p ([]:rest) = loop (p+1) rest -- Discard blank
   -- Ok, this is kind of weird... Text.CSV parses a trailing blank line
   -- as having one field of zero size:
   loop p ([""]:rest) = loop (p+1) rest 
   loop pos (row:rest)
     | length row == numCols = row : loop (pos+1) rest
     | otherwise = error $ "error in validateCSV: encountered on row #"++ show pos
                   ++ "\nRow did not contain the expected number of columns: "++show numCols
                   ++"\nCSV schema was:\n  "++show header
                   ++"\nOffending row (length "++show (length row)++") was:\n  "++show row

-- | Summarize each column
printSummary :: ValidatedCSV -> IO ()
printSummary ValidatedCSV{header,rows} = do 
  chatter "Printing summary of each column:"
  hPutStrLn stderr "   --------------------------------------------------------------------------------"
  forM_ rotated $ \ (hdr:vals) -> do
     let uniques = S.toAscList $ S.fromList vals
     hPutStrLn stderr $ "   "++hdr++": "++ summarize 300 (show uniques)
  hPutStrLn stderr "   --------------------------------------------------------------------------------\n"
  where
    rotated = L.transpose (header:rows)


summarize :: Int -> String -> String
summarize limit str =
  case L.splitAt limit str of
    (hd,[]) -> hd
    (hd,_)  -> hd ++ "..."


fst3 :: (t, t1, t2) -> t
fst3 (a,_,_) = a


readDbl :: String -> Double
readDbl s =
  case reads s of
    (d,_):_ -> d
    _ -> error $ "Could not parse string as a Double: "++s    

readInt :: String -> Int
readInt s =
  case reads s of
    (x,_):_ -> x
    _ -> error $ "Could not parse string as an Int: "++s
    

