{-# LANGUAGE DeriveDataTypeable #-}
{-# LANGUAGE FlexibleInstances #-}
{-# LANGUAGE RecordWildCards #-}
{-# LANGUAGE NamedFieldPuns #-}
{-# LANGUAGE BangPatterns #-}
{-# LANGUAGE CPP #-}

module Main where

import Control.Exception
-- import Control.Lens
import Control.Monad (unless,when,forM_)
import Data.Char (isNumber)
-- import Data.Colour
-- import Data.Colour.Names
-- import Data.Default.Class

import Control.DeepSeq (force)
import Data.List (elemIndex, intersperse, delete, intercalate, isInfixOf)
import qualified Data.List as L
import Data.List.Split (splitOn)
import qualified Data.Map as M
import Data.Maybe (catMaybes, fromMaybe, listToMaybe)
import Data.String.Utils (strip)
import qualified Data.Set as S
import Data.Typeable
import Data.Version (showVersion)
import Prelude hiding (init)
import System.Console.GetOpt (getOpt', ArgOrder(Permute), OptDescr(Option), ArgDescr(..), usageInfo)
import System.Environment (getArgs, getProgName)
-- import System.Exit (exitFailure, exitSuccess)
import System.IO (hPutStrLn, stderr, stdin, hGetContents)
import System.IO.Unsafe (unsafePerformIO)
import System.FilePath (replaceExtension)
import System.Process (system)
import System.Exit
import qualified Text.CSV as CSV

import Debug.Trace

-- Generated by cabal:
import Paths_hsbencher_graph(version) -- getDataDir

#ifdef USECHART
-- Charting library
import Graphics.Rendering.Chart as C
import Graphics.Rendering.Chart as C
import qualified Graphics.Rendering.Chart.Backend.Cairo as Cairo
import Graphics.Rendering.Chart.Easy as C
#endif

---------------------------------------------------------------------------
--


{- DEVLOG
  - 11 March 2015: Added Points to GraphMode

  - 20 Nov 2014: Starting some simplifications and cleanups


-}

{- Random junk
cabal install HSBencher/hsbencher-tool/ HSBencher/hsbencher-graph/ --bindir=/home/joels/Current/ObsidianWriting/Winter2014/bin/ --force-reinstalls
cat ./text/data/Scan-cse-324974-663.csv | ./bin/grapher -o apa.png --key="ARGS0" --key="ARGS1" -x ARGS2 -y runtime

-}


-- Some data types for safer CSV handling.
---------------------------------------------------------------------------

-- | CSV data where all rows have the right number of entries.
data ValidatedCSV =
     ValidatedCSV { header :: [CSV.Field]
                  -- TODO: add ixMap that maps each key onto an index or indexing function into a row.
                  -- This is currently redundantly computed in various places.
                  , rows   :: [CSV.Record]
                  }
  deriving Show
     
-- | A single validated row, not a whole table.  But like
-- ValidatedCSV, this includes the header information.
data ValidatedRow = ValidatedRow { row_header :: [CSV.Field]
                                 , row_contents :: CSV.Record }

instance Show ValidatedRow where
  show (ValidatedRow h r) = show (zip h r)
    

-- | If a CSV is filtered down to one row, cast it to a row.
fromSingleton :: ValidatedCSV -> Maybe ValidatedRow
fromSingleton ValidatedCSV{header, rows=[x]} = Just (ValidatedRow header x)
fromSingleton _ = Nothing

toRows :: ValidatedCSV -> [ValidatedRow]
toRows (ValidatedCSV hdr rows) = [ ValidatedRow hdr r | r <- rows ]

-- | Groups of rows chunked together by "key"
data KeyedCSV =
     KeyedCSV { keys    :: [ColName]
              , kheader :: [CSV.Field]
              , krows   :: M.Map Key [CSV.Record] }

-- Keys
--------------------------------------------------------------------------------           

-- | A combination of field values, printed as A_B_C, stored as a String.
data Key = Key [(ColName,CSV.Field)] deriving (Eq,Ord)
instance Show Key where
  show (Key ls) = keyPrint $ L.map snd ls


-- | Encode the policy for printing keys in a human readable way.
keyPrint :: [String] -> String
keyPrint = concat . intersperse "_" . filter (/="")

-- | A key as displayed to the user, in A_B_C printed form.
type RenderedKey = String
         
-- newtype Key = Key String  deriving (Eq,Ord)
-- instance Show Key where
--     show (Key s) = show s

keyLookup :: ColName -> Key -> String
keyLookup col (Key kls) = 
    case L.lookup col kls of
      Just v -> v
      Nothing -> error $ "keyLookup: could not find column "++col++
                         "\n in key containing: "++show kls

-- | Project the designated key fields out of a row, yielding a Key.
toKey :: [ColName] -> ValidatedRow -> Key
toKey cols row = Key [ (c, row #! c) | c <- cols]

-- | Parse a key given the names of the key fields and the printed
-- A_B_C representation of the key values.
parseKey :: [ColName] -> String -> Key
parseKey cols str =
    Key (fragileZipWith (\ x y -> (x,y)) cols (splitOn "_" str))

--------------------------------------------------------------------------------           


type ColName = String

-- | For now we only pattern match by string inclusion.  TODO: support regexps?
type Pattern = String

-- | Which columns contain the error data.
data ErrorCols = ErrDelta  ColName
                  -- ^ Symmetric error range needing only one number.
               | ErrMinMax { errmin:: ColName,  errmax:: ColName }
                  -- ^ Find the MIN and MAX Y value in the specified columns.
  deriving (Show,Eq,Read,Ord)

-- | The error around a specific point in a given dimension can be
-- either a delta or *bounds*.
data ErrorVal = NoError
              | DeltaVal  Double
              | MinMaxVal Double Double
  deriving (Show,Eq,Read,Ord)

-- | Command line flags to the executable.
data Flag = ShowHelp
          | ShowVersion -- TODO: implement this

          | OutFile  FilePath

            -- TODO: move this functionality over to a separate executable:
          | DumpFile FilePath -- Dump validated/filtered CSV, in addition to extracted plot.
          | Summary

          | RenderMode GraphMode
          | Title  String
          | XLabel String
          | YLabel String

          -- Log mode
          | YLog  -- logarithmic scale on y-axis
          | XLog  -- logarithmic scale on x-axis

          -- identify part of a key
          | KeyCol  { col :: ColName } -- --key="Arg1" --key="Arg2" means Arg1_Arg2 is the name of data series
          | XValues { col :: ColName } -- column containing x-values
          | YValues { col :: ColName } -- column containing y-values

          | YErrValues ErrorCols

          | FilterContain { col :: ColName, pats :: [Pattern] }
          | FilterEq      { col :: ColName, pats :: [String] }

          | FilterRange  { col :: ColName, minVal :: Double, maxVal :: Double }

          | Pad    { col :: ColName, padTo :: Int }
          | Renames FilePath

          -- output resolution
          | XRes String
          | YRes String

          -- output format
          | OutFormat MyFileFormat

          | GnuPlotTemplate FilePath

          -- Resolving/aggregating duplicates or performing comparisons:
          | Latest  { col :: ColName }
          | Speedup { col :: ColName, contains :: Pattern }
          | Vs      { col :: ColName, contains :: Pattern }


          | NormaliseKey String
            -- ^ Normalize against a line, produce a factor plot.

          | Ratio        NormValueSpec
            -- ^ Normalize against a single value: a single line point.
          | InverseRatio NormValueSpec
            -- ^ Normalize against a single value: a single line point.

          -- TODO: More general way to map simple functions over points.

          | DummyFlag

          --   -- Aux values are not plotted!
          -- | AuxFile String -- a single auxfile that need not have same format as other CSV
          -- | AuxKey  String -- part of key into auxfile
          -- | AuxX    String -- column with aux x value
          -- | AuxY    String -- column with aux y value
  deriving (Eq,Ord,Show)

-- data ValueSpec = ValueSpec { valkey :: Key, valX :: SeriesDatum }
--   deriving (Eq,Ord,Show)

-- | A ValueSpec is a comma-separated list of COL=VAL settings, or COL
-- entries by themselves.  COL=VAL is a filter, whereas COL alone
-- indicates a GROUPBY, where different values of COL receive different normalization values
data NormValueSpec = NormValueSpec [(ColName, Maybe String)]
  deriving (Eq,Ord,Show)

-- This is all a bit unfortunate.
data MyFileFormat = MySVG | MyPNG | MyPDF | MyPS
                  | MyCSV
                  | MyGPL
                  deriving (Eq, Ord, Show, Read)

#ifdef USECHART
convToFileFormat :: MyFileFormat -> Cairo.FileFormat
convToFileFormat MySVG = Cairo.SVG
convToFileFormat MyPDF = Cairo.PDF
convToFileFormat MyPNG = Cairo.PNG
convToFileFormat MyPS  = Cairo.PS
convToFileFormat MyCSV = error "Cairo does not do CSV output"
#endif

data GraphMode = Bars | BarClusters | Lines | Points
               deriving (Eq, Ord, Show, Read )

-- | Type of values stored in a series
data ValueType = Int | Double | String
               deriving (Eq, Ord, Show, Read )


-- Once things start to work more properly, exception handling should be made proper.
-- | Exceptions that may occur
data Error
  = FlagsNotValidE String
    deriving (Show, Typeable)

instance Exception Error

-- | For now this application is hardcoded to use a particular
-- separator in both rename files and command line arguments.
universalSeparator :: String
universalSeparator = ","

{-# NOINLINE progName #-}
progName :: String
progName = unsafePerformIO getProgName

-- | Parse the comma-separated "COL,VAL" string.
parseFilter :: String -> (ColName,[String])
parseFilter s =
  case splitOn universalSeparator s of
    (l:r1:rest) -> (l,r1:rest)
    _ -> error $ "--filter argument expected at least two strings separated by commas, not: "++s


parseFilterRange :: String -> Flag
parseFilterRange s =
  case splitOn universalSeparator s of
    [col,mn,mx] ->
        case (reads mn, reads mx) of
          ((mn',_):_,(mx',_):_) -> FilterRange col mn' mx'
          _ -> err
    _ -> err
 where
   err = error $ "--filtRange argument expected a column and two numbers separated by commas, not: "++s

parseNormValueSpec :: String -> NormValueSpec
parseNormValueSpec s =
   case splitOn universalSeparator s of
     ls -> NormValueSpec [ parse x | x <- ls ]
 where
   parse str =
       case splitOn "=" str of
         [col]     -> (col,Nothing)
         [col,val] -> (col,Just val)
         _ -> error$ "not a valid spec for --ratio/--inverse-ratio: "++str
          
-- parseValueSpec :: String -> ValueSpec
-- parseValueSpec s =
--    case splitOn universalSeparator s of
--      [linekey,xval] -> ValueSpec (Key linekey) (toSeriesDatum xval)
--      _ -> error$ "not a valid POINT for --ratio/--inverse-ratio: "++s

          
parseAssigns :: String -> [(String,String)]
parseAssigns s0 = [ case splitOn "=" assn of
                        [lhs,rhs] -> (lhs,rhs)
                        _ -> error $ "bad COL=VAL specification: " ++s0
                    | assn <- splitOn universalSeparator s0 ]

parseErrCols :: String -> ErrorCols
parseErrCols s =
  case splitOn universalSeparator s of
    [one]   -> ErrDelta one
    [mn,mx] -> ErrMinMax mn mx
    _ -> error $ "--filter argument expected at least two strings separated by commas, not: "++s

parsePad :: String -> (String,Int)
parsePad s =
  case splitOn universalSeparator s of
    [l,r] -> case reads r of
              [(n,"")] -> (l,n)
              _ -> error $ "--filter could not parse this as an integer: "++r
    _ -> error $ "--filter argument expected to be two strings separated by one comma, not: "++s

-- | Command line options.
core_cli_options :: [OptDescr Flag]
core_cli_options =
     [ Option ['h'] ["help"]    (NoArg ShowHelp)         "Show this help message and exit."
     , Option []    ["version"] (NoArg ShowVersion)      "Show version and exit."
     , Option ['o'] ["out"]  (ReqArg OutFile "FILE")     "Specify result file for main output"

     , Option [] ["cleaned"] (ReqArg DumpFile "FILE")  "Write a cleaned, filtered version of the orig CSV here."
     , Option [] ["summary"] (NoArg Summary)           "After cleaning, print a summary of each column to stderr."

     , Option []    []    (NoArg DummyFlag) "\n Data Handling options"
     , Option []    []    (NoArg DummyFlag) "--------------------------------"

     , Option ['k'] ["key"]    (ReqArg KeyCol  "STR")      "Columns that make part of the key"
     , Option ['x'] ["xvalue"] (ReqArg XValues "STR")      "Column containing x values"
     , Option ['y'] ["yvalue"] (ReqArg YValues "STR")      "Column containing y values"

     -- TODO: especially when using this for CSV->CSV operations.
     -- Allowing multiple dependent variables seems like a good idea.

     , Option [] ["error"] (ReqArg (YErrValues . parseErrCols) "STR") $
       "Column containing error for Y dimension.  Either 'COl1,COL2' for\n"++
       "separate lower/upper bounds or just 'COL' for Y-delta."

     --  Not ready yet:
     , Option [] ["filtContain"] (ReqArg (uncurry FilterContain . parseFilter) "COL,VAL1,VAL2..") $
       "Filter leaving only rows where COL contains one\n" ++
       "of VAL1..VALN as a substring."

     , Option [] ["filtEq"] (ReqArg (uncurry FilterEq . parseFilter) "COL,VAL1,VAL2..") $
       "Filter leaving only rows where COL is exactly equal\n" ++
       "to one of VAL1, or exactly equal to VAL2, etc."

     , Option [] ["filtRange"] (ReqArg parseFilterRange "COL,VAL1,VAL2") $
       "Filter leaving only rows where COL is between VAL1 and VAL2 inclusive.\n" ++
       "This requires that all cells in COL are numeric values."

     -- , Option [] ["sort"] (ReqArg () "STR") $
     --  "Name of a numeric field by which to sort the lines."

     , Option [] ["pad"] (ReqArg (uncurry Pad . parsePad) "COL,N") $
     "Treat COL as a numeric column, and pad numbers to\n"++
     "N characters, preppending leading zeros."

     , Option [] ["renames"] (ReqArg Renames "FILE") $
       "Provide a comma-separated file where each line is an\n" ++
       "OLD,NEW pair indicating renames for data series' names"


     , Option []    []    (NoArg DummyFlag) "\n Resolving duplicates and making comparisons"
     , Option []    []    (NoArg DummyFlag) "----------------------------------------------"

     , Option [] ["latest"] (ReqArg Latest "STR") "Grab latest data point according to monotonically increasing column."

 -- TODO: and also move this over to a separate CSV->CSV executable:
     -- , Option [] ["speedup"] (ReqArg (uncurry Speedup . parseFilter) "KEY,VAL") $ ""
     -- , Option [] ["vs"] (ReqArg (uncurry Vs . parseFilter) "KEY,VAL") $ ""

     , Option []    []    (NoArg DummyFlag) "\n Presentation options"
     , Option []    []    (NoArg DummyFlag) "--------------------------------"

-- Not finished yet, don't mention [2015.02.22]:
--     , Option []    ["bars"] (NoArg (RenderMode Bars))       "Plot data as bars"
--     , Option []    ["barclusters"] (NoArg (RenderMode BarClusters)) "Plot data as bar clusters"

     , Option []    ["points"] (NoArg (RenderMode Points))   "Plot data as points"
     , Option []    ["lines"] (NoArg (RenderMode Lines))     "Plot data as lines"

     , Option []    ["title"] (ReqArg Title "String")        "Plot title"
     , Option []    ["xlabel"] (ReqArg (XLabel . deUnderscore) "String")      "X-axis label"
     , Option []    ["ylabel"] (ReqArg (YLabel . deUnderscore) "String")      "Y-axis label"

     -- Logarithmic scales
     , Option []     ["ylog"] (NoArg YLog)                "Logarithmic scale on y-axis"
     , Option []     ["xlog"] (NoArg XLog)                "Logarithmix scale on x-axis"

     , Option []    ["CSV"]    (NoArg (OutFormat MyCSV)) "Output raw CSV data to file selected by --out"

#ifdef USECHART
     , Option []    []    (NoArg DummyFlag) "\n Haskell Chart specific options"
     , Option []    []    (NoArg DummyFlag) "--------------------------------"

     -- plot configuration
     , Option []    ["xres"]   (ReqArg XRes "String")    "X-resolution of output graphics"
     , Option []    ["yres"]   (ReqArg XRes "String")    "Y-resolution of output graphics"
     , Option []    ["SVG"]    (NoArg (OutFormat MySVG)) "Output in SVG format"
     , Option []    ["PDF"]    (NoArg (OutFormat MyPDF)) "Output in PDF format"
     , Option []    ["PS"]     (NoArg (OutFormat MyPS))  "Output in PS format"
     , Option []    ["PNG"]    (NoArg (OutFormat MyPNG)) "Output in PNG format"

#else
     , Option []    []    (NoArg DummyFlag) "\n Haskell Chart support not compiled in!  No options."
     , Option []    []    (NoArg DummyFlag) "-----------------------------------------------------"
#endif

     , Option []    []    (NoArg DummyFlag) "\n Normalisation:"
     , Option []    []    (NoArg DummyFlag) "----------------"


     , Option []    ["factor"] (ReqArg NormaliseKey "KEY")
                     (unlines
                      [ "A factor plot: the ratio of each line to a designated baseline."
                      , "The KEY must be a string, e.g. \"A_B_C\" where A B and C "
                      , "are values for the --key columns, in order."
                      , "This KEY identifies which line is the baseline." ])
     , Option []    ["ratio"] (ReqArg (Ratio . parseNormValueSpec) "POINT")
                     (unlines
                      ["Report the ratio of each datapoint divided by a constant. "
                      ,"The constant normalization value is selected by POINT. "
                      ,"This is appropriate for 'bigger=better' plots. "
                      ,"POINT is of the form kEY,VAL, where KEY is formatted "
                      ,"so as to select a line (see --factor), and VAL is the X-value "
                      ,"that selects which point (Y value) on the line becomes "
                      ,"the normalization constant."])
     , Option []    ["inverse-ratio"] (ReqArg (InverseRatio . parseNormValueSpec) "POINT")
                     ("The inverse of --ratio.  That is, report a "++
                      "constant divided by each datapoint, respectively." ++
                      "The constant normalization value is selected by POINT, formatted as in --ratio."++
                      "This is appropriate for 'smaller=better' plots."
                     )

     , Option []    []    (NoArg DummyFlag) "\n GNUPlot Options:"
     , Option []    []    (NoArg DummyFlag) "------------------"

     , Option []    ["GPL"] (NoArg (OutFormat MyGPL))  "Output a .gpl plot script + CSV data."
     , Option []    ["template"] (ReqArg GnuPlotTemplate "FILE") "Prepend FILE to generated gnuplot scripts."

     ]

-- | A complete hack to make it easier to pass in multi-word labels in
-- bash scripts.  Turn underscores into spaces.
deUnderscore :: String -> String
deUnderscore = L.map f
  where
    f '_' = ' '
    f  c  = c

-- | Multiple lines of usage info help docs.
fullUsageInfo :: String
fullUsageInfo = usageInfo docs core_cli_options
 where
  docs = "USAGE: "++progName++" <flags> ... <inputCSVfiles> ...\n"++
         "Version: "++showVersion version++"\n"++

         "\nA utility for plotting datasets retrieved from HSBencher (using standard HSBencher Schema).\n"++
         "\nReads CSV data from stdin if no input files are given.\n\n"++

         "Basic usage guide:\n"++
         " \n"++
         "\n"++
         "Currently incomplete functionality: :\n"++
         " * bar charts are not supported in gnuplot output\n"++

         "\nCommand line flags: \n"
--   ++ generalUsageStr

---------------------------------------------------------------------------
-- Data representations
---------------------------------------------------------------------------
data SeriesDatum = IntData Int
                 | NumData Double
                 | StringData String
                  deriving (Show, Eq, Read)

instance Ord SeriesDatum where
 IntData x <= IntData y = x <= y
 NumData x <= NumData y = x <= y
 IntData x <= NumData y = fromIntegral x <= y
 NumData x <= IntData y = x <= fromIntegral y
 StringData x <= _ = error $ "Ord: cannot compare string data: "++ x
 _ <= StringData y = error $ "Ord: cannot compare string data: "++ y

convertToString :: SeriesDatum -> String
convertToString (IntData x) = (show x)
convertToString (NumData x) = (show x)
convertToString (StringData a) = a

isNum :: SeriesDatum -> Bool
isNum (NumData _) = True
isNum _ = False

seriesType :: SeriesDatum -> ValueType
seriesType (IntData _) = Int
seriesType (NumData _) = Double
seriesType (StringData _) = String

class FromData a where
  fromData :: SeriesDatum -> a

instance FromData Double where
  fromData (NumData a) = a
  fromData (IntData n) = fromIntegral n -- RRN: TEMP: sanity check this.  Allow Int to "subtype" as double.
  fromData e = error $ "FromData Double, could not parse as Double: "++show e

instance FromData Int where
  fromData (IntData a) = a
  fromData e = error$ "FromData Int, could not parse: "++show e

instance FromData String where
  fromData (StringData a) = a
  fromData e = error "FromData String, could not parse: "++show e

---------------------------------------------------------------------------
-- Data series
---------------------------------------------------------------------------

-- | These correspond to lines in the plot: named progressions of (x,y) pairs.
type DataSeries = M.Map Key [LinePoint]
data LinePoint = LinePoint { x::SeriesDatum, y::SeriesDatum, err::ErrorVal }
  deriving (Eq,Show,Ord,Read)

insertVal :: DataSeries -> Key -> LinePoint -> DataSeries
insertVal m key val =
  case M.lookup key m of
    Nothing   -> M.insert key [val] m
    Just vals -> M.insert key (val:vals) m


---------------------------------------------------------------------------
-- Plot configuration
---------------------------------------------------------------------------
data PlotConfig = PlotConfig { plotOutFile    :: FilePath
                             , plotOutFormat  :: MyFileFormat
                             , plotResolution :: (Int,Int)
                             , plotTitle      :: String
                             , plotXLabel     :: String
                             , plotYLabel     :: String
                             , plotYLog       :: Bool
                             , plotXLog       :: Bool
                             , plotErrorCols  :: Maybe ErrorCols
                             , gnuPlotTemplate :: Maybe FilePath
                             , plotMode       :: GraphMode
                             }
                  deriving (Show, Eq, Read, Ord)

chatter :: String -> IO ()
chatter str = hPutStrLn stderr $ " [hsbencher-graph] " ++str

---------------------------------------------------------------------------
-- MAIN
---------------------------------------------------------------------------
main :: IO ()
main = do
  args <- getArgs

  let (options, inFiles, unrec,errs) = getOpt' Permute core_cli_options args

      normaliseKeyFlags = [ x | x@NormaliseKey{} <- options]
      ratioFlags        = [ x | x@Ratio{} <- options]
      inverseRatioFlags = [ x | x@InverseRatio{} <- options]

      xRes = head $ [readInt x | XRes x <- options] ++ [800]
      yRes = head $ [readInt y | YRes y <- options] ++ [600]

      plotTitle = head $ [t | Title t <- options] ++ ["NO_TITLE"]
      xLabel    = head $ [l | XLabel l <- options] ++
                         [c | XValues c <- options] ++
                         ["X-Axis"] -- Last resort, default
      yLabel    = head $ [l | YLabel l <- options] ++
                         [c | YValues c <- options] ++
                         ["Y-Axis"]

      -- Should any axis be log scale
      y_logscale = (not . null) [() | YLog <- options]
      x_logscale = (not . null) [() | XLog <- options]

  outFormat <- case [ format | OutFormat format <- options] of
                 []  -> do chatter$ "Warning: no output format selected.  Defaulting to CSV output."
                           return MyCSV
                 [x] -> return x
                 ls  -> error$ "multiple output formats not yet supported: "++show ls

  unless (null errs) $ do
    chatter$ "Errors parsing command line option(s):"
    mapM_ (putStr . ("   "++)) errs
    exitFailure
  unless (null unrec) $ do
    chatter$ "Unrecognized command line option(s):"
    mapM_ (putStr . ("   "++)) unrec
    exitFailure

  when (ShowHelp `elem` options) $ do
    putStrLn fullUsageInfo
    exitSuccess
  when (ShowVersion `elem` options) $ do
    putStrLn $ progName ++ ": version "++showVersion version
    exitSuccess

  --------------------------------------------------
  -- Get target
  let outFile = fromMaybe (error  "Error: an output file has to be specified") $
                listToMaybe [file | OutFile file <- reverse options]

  --------------------------------------------------
  -- Get keys, in order
  let hasKey  = (not . null) [ () | KeyCol _ <- options]
      keyCols =
        case hasKey of
          False -> error "No key specified"
          True  -> [ q | KeyCol q <- options]

  let hasX    = (not . null) [ () | XValues _ <- options]
      hasY    = (not . null) [ () | YValues _ <- options]

      plotErrorCols = listToMaybe [ e | YErrValues e <- options ]
      xyerr =
        case hasX && hasY of
          False -> error "Both -x and -y arguments are needed"
          True  -> (head [x | XValues x <- options],
                    head [y | YValues y <- options],
                    plotErrorCols )

      gnuPlotTemplate = head $ [ Just f | GnuPlotTemplate f <- options] ++ [Nothing]

      renderModes = [ x | RenderMode x <- options]

  renderMode <-
    case renderModes of
      [] -> do
        chatter $ "No mode (--lines, --points) specified. Defaulting to draw lines"
        return Lines
      [x] -> return x
      (x:_) -> do
        chatter $ "More than one mode specified. Using " ++ show x
        return x

  --------------------------------------------------
  -- All the collected parameters for the plotting.
  let plotConf = PlotConfig outFile
                            outFormat
                            (xRes,yRes)
                            plotTitle
                            xLabel
                            yLabel
                            y_logscale
                            x_logscale
                            plotErrorCols
                            gnuPlotTemplate
                            renderMode

  --------------------------------------------------
  -- Acquire data:

  -- Input files must have same CSV layout
  -- and same format as any CSV arriving in pipe:
  rawdat <- case inFiles of
             []    -> do str <- hGetContents stdin
                         chatter$ "Reading CSV from stdin... "
                         return $ CSV.parseCSV "stdin" str
             [one] -> do chatter$ "Reading CSV from input file: "++one
                         CSV.parseCSVFromFile one
             _     -> error$ "doesn't currently support reading from multiple files: "++show inFiles

  dat0 <- case rawdat of
            Left err -> error $ "Error parsing CSV data: \n"++show err
            Right d  -> do chatter$ "Successfully parsed CSV input dataset."
                           return d
  let dat1 = validateCSV dat0
      dat2 = doFilters options dat1
      dat3 = doPadding [ (c,n) | Pad c n <- options ] dat2
      dat4 :: ValidatedCSV
      dat4 = case [ c | Latest c <- options] of
               []  -> dat3
               [c] -> -- Here we must not collapse variation in the X axis:
                      takeLatest (fst3 xyerr : keyCols) c dat3
               ls  -> error $ "Error: More than one --latest provided: "++show ls
  chatter $ "After validation, read total rows: " ++ show (length (rows dat1))
  _ <- evaluate (force (rows dat4))  -- Flush out error messages.
  chatter $ "Data filtering completed successfully, rows remaining: " ++ show (length (rows dat2))
  chatter $ "After padding and taking --latest into account: " ++ show (length (rows dat4))
  forM_ [ f | DumpFile f <- options ] $ \fl -> do
    chatter $ "Writing cleaned/filtered copy of CSV data to: "++fl
    writeFile fl (CSV.printCSV (fromValidated dat4))

  unless (null [ () | Summary <- options ]) $ printSummary dat4

  -- Now for the LOSSY step where we project out just what we care to plot:
  (csv,aux) <- extractData keyCols xyerr dat4
  chatter $ "Data series extracted, number of lines: " ++ show (M.size csv)

  chatter$ "Here is a sample of the CSV before renaming and normalization:\n" ++
    unlines [ "    "++take 100 (show l)++"..." | l <- (take 5 (M.toList csv))] ++ "    ...."
  chatter$ "Also, a sample of discarded rows missing X datapoints: "++ take 500 (show aux)

  --------------------------------------------------
  -- Data preprocessing / munging:

  renameTable <- fmap (concatMap lines) $
                 mapM readFile [f | Renames f <- options]
  let series1 :: [(Key,[LinePoint])]
      series1 = M.assocs csv

      series2     = map unifyTypes series1
      series_type = typecheck series2

      -- normalise values against this datapoint
      normKey = let [x] = [nom | NormaliseKey nom <- options] in
                parseKey keyCols x
      base = csv # normKey -- The entire data series which we normalize against
        
      plot_series0 =
          let (_,ycol,_) = xyerr in
          case normaliseKeyFlags ++ ratioFlags ++ inverseRatioFlags of
            [NormaliseKey{}] -> normalise base series2
            [Ratio whichval] -> mapPoints (\ky pt -> let val = fromData (findNorm (ky,ycol) whichval dat4) in
                                            onY (\y -> NumData (fromData y / val)) pt)
                                          series2
            [InverseRatio whichval] -> mapPoints
                                       (\ky pt -> let val = fromData (findNorm (ky,ycol) whichval dat4) in
                                                  onY (\y-> NumData (val/fromData y)) pt)
                                       series2

            [] -> series2
            ls -> error $ "Expected only one of --factor, --ratio, --inverse-ratio, got:\n"++show ls

      renamer = buildRenamer renameTable
      plot_series :: [(RenderedKey, [LinePoint])]
      plot_series = [ (renamer nm,dat) | (nm,dat) <- plot_series0 ]

  chatter$ "Inferred types for X/Y axes: "++show series_type
--           "\n From series: "++show series2

  --------------------------------------------------
  -- do it
  case (outFormat, series_type) of
    (_,Nothing) -> error $ "Series failed to typecheck"
    (MyCSV, _)  -> writeCSV plotConf plot_series
    (MyGPL, _)  -> do chatter "Writing out both CSV file and a GnuPlot script to plot it."
                      writeCSV     plotConf plot_series
                      writeGnuplot plotConf plot_series
#ifdef USECHART
    (_,Just (Int,Int))       -> plotIntInt plotConf plot_series
    (_,Just (Int,Double))    -> plotIntDouble plotConf plot_series
    (_,Just (Double,Double)) -> plotDoubleDouble plotConf plot_series
#endif
    (_,Just (_,_)) -> error $ "no support for plotting of this series type: "++show series_type++
                              ", with this output format: "++show outFormat

-- | Operate only on the Y data
onY :: (SeriesDatum -> SeriesDatum) -> LinePoint -> LinePoint
onY fn lp@LinePoint{y} = lp { y = fn y }

---------------------------------------------------------------------------
-- Plotting


-- | Don't produce an actual chart, rather write out the data as CSV.
writeCSV :: PlotConfig -> [(RenderedKey, [LinePoint])] -> IO ()
-- Assumes a shared and sensible X axis for all data series.
writeCSV PlotConfig{..} series = do
  -- ASSUMPTION: we assume a sensible Ord instance for
  -- SeriesDatum... that makes possible unfair assumptions about
  -- "deriving":
  let allKeys = map convertToString $
                S.toAscList $ S.fromList $ concatMap ((map x) . snd) series
      -- Format:  all data columns before all error columns:
      header = [plotXLabel] ++ yCols ++ yErrs
      yCols  = map (show . fst) series
      yErrs  = case plotErrorCols of
                 Nothing -> []
                 Just (ErrDelta _)    -> map (++"_Err")     yCols
                 Just (ErrMinMax _ _) -> map (++"_ErrLow")  yCols ++
                                         map (++"_ErrHigh") yCols

      -- nested map from key -> x -> (y,yErr)
      alldata = M.map (\prs -> M.fromList
                        [ (convertToString x, (convertToString y, err)) | LinePoint{x,y,err} <- prs ] ) $
                M.fromList series

      rows = [ key : buildRow key | key <- allKeys ]

      buildRow key =
        let gogo f = [ case M.lookup key seriesMap of
                        Nothing -> "" -- TODO, make configurable.  Missing data for this X value in this line.
                        Just dat -> f dat
                     | (seriesName, _) <- series
                     , let seriesMap = alldata M.! seriesName ]
        in
        -- Row has Y values then Y errors:
        gogo fst ++
        case plotErrorCols of
          Nothing              -> []
          Just (ErrDelta _)    -> gogo (\ (_,DeltaVal d) -> show d)
          Just (ErrMinMax _ _) -> gogo (\ (_,MinMaxVal mn _) -> show mn) ++
                                  gogo (\ (_,MinMaxVal _ mx) -> show mx)

      csvResult = CSV.printCSV (header:rows)
  chatter $ "Writing out CSV for "++show (length series)++" data series (lines) named: "++unwords (tail header)
  writeFile plotOutFile csvResult
  chatter $ "Successfully wrote file "++show plotOutFile


-- | Combine the template file with the generated script and write it out to the appropriate file on disk.
writeGnuplot :: Show a => PlotConfig -> [(a, t)] -> IO ()
writeGnuplot cfg@PlotConfig{..} series = do
  let gplfile = replaceExtension plotOutFile "gpl"
      gplLines = lines (buildGnuplot cfg series)
  chatter $ "Writing out Gnuplot script as well as CSV: "++gplfile
-- TODO, make this into a library and look up the template file in ~/.cabal/share (from the Paths_ module)
--      defaultTemplate = "template.gpl"
  let
      defaultTemplate = error "ERROR: For now you must provide GnuPlot template with --template"
      template = fromMaybe defaultTemplate gnuPlotTemplate

  -- FIXME: assumes the template is in the current directory.  Use a more principled way:
  prelude <- fmap lines $ readFile template
  writeFile gplfile (unlines (prelude ++ gplLines))
  chatter $ "Successfully wrote file "++show gplfile

  let cmd = "gnuplot "++gplfile
  chatter $ "Attempting to use gnuplot command to build the plot:"++show cmd
  cde <- system cmd
  case cde of
    ExitSuccess   -> chatter "Gnuplot returned successfully."
    ExitFailure c -> chatter$ "WARNING: Gnuplot process returned error code: "++show c
  return ()

-- | Build the body of the gnuplot file.  Actually it's the /suffix/ given that we prepend a header.
buildGnuplot :: Show a => PlotConfig -> [(a, t)] -> String
buildGnuplot PlotConfig{plotTitle, plotXLabel, plotYLabel, plotXLog, plotYLog, plotOutFile, plotMode,plotErrorCols}
             series = unlines gplLines
  where
      gplLines = [ "\n# Begin "++progName++" generated script:"
                 , "set title "++ show plotTitle
                 , "set xlabel "++ show plotXLabel
                 , "set ylabel "++ show plotYLabel
                 , if plotXLog then "set log x" else ""
                 , if plotYLog then "set log y" else ""
                 , "set output "++ show (replaceExtension plotOutFile "pdf")
                 , "# And because we're plotting CSV data:"
                 , "set datafile separator \",\""
                 , "plot "++ concat (intersperse ", \\\n     "
                   -- Line them up carefully by position:
                   (concat [ mkPlotClauses seriesName ind
                           | ((seriesName, _),ind) <- zip series [2::Int ..] ]))
                 ]
      numSeries = length series
      mkPlotClauses seriesName ind =
        case plotMode of
          Lines ->
            let basicLine sty = show plotOutFile++" using 1:"++show ind ++
                                " title "++show seriesName++" w "++sty++" ls "++show(ind-1)
                errorStyle = " notitle with yerrorbars ls 99 " -- ++show(ind-1)
            in
             case plotErrorCols of
               Nothing -> [ basicLine "linespoints" ]
               Just (ErrDelta _) ->
                 [ basicLine "lines"
                 , show plotOutFile++" using 1:"++show ind++":"++
                   show (ind + numSeries) ++ errorStyle
                 ]
               Just (ErrMinMax _ _) ->
                 [ basicLine "lines"
                 , show plotOutFile++" using 1:"++show ind++":"++
                   show (ind + numSeries)++":"++show (ind + 2*numSeries)++
                   errorStyle
                 ]
          Points -> [show plotOutFile++" using 1:"++show ind ++
                     " title "++show seriesName++" w points ps "++show(ind-1)]

          Bars{}        -> error "FINISHME: Gnuplot / Bars"
          BarClusters{} -> error "FINISHME: Gnuplot / BarClusters"

      -- usingClause ind =
      --   case plotErrorCols of
      --     Nothing -> "using 1:"++show ind
      --     Just (ErrDelta _)    -> "using 1:"++show ind++":"++
      --                             show (ind + numSeries) ++ " with yerrorbars"
      --     Just (ErrMinMax _ _) -> "using 1:"++show ind++":"++
      --                             show (ind +   numSeries)++":"++
      --                             show (ind + 2*numSeries) ++ " with yerrorbars"



#ifdef USECHART
plotIntInt :: PlotConfig -> [(Key, [(SeriesDatum, SeriesDatum)])] -> IO ()
plotIntInt conf series = error "hsbencher-graph: plotIntInt not implemented!"

plotIntDouble :: PlotConfig -> [(Key, [(SeriesDatum, SeriesDatum)])] -> IO ()
plotIntDouble conf  series = do
  let fopts = Cairo.FileOptions (plotResolution conf)
                                (convToFileFormat (plotOutFormat conf))
  Cairo.toFile fopts (plotOutFile conf) $ do

    -- 13 colors
    setColors $ map opaque
              [blue, green, orange, red
              ,brown, black, darkblue, darkgray
              ,darkgreen, darkorange, darkred, yellow, violet]

    layout_title .= plotTitle conf
    layout_background .= solidFillStyle (opaque white)
    layout_foreground .= opaque black
    layout_left_axis_visibility . axis_show_ticks .= True
    layout_title_style . font_size .= 24

    if (plotYLog conf)
      then layout_y_axis . laxis_generate .= autoScaledLogAxis (LogAxisParams show)
      else return ()


    -- Not Possible in IntDouble plot
    --if (plotXLog conf)
    --   then layout_x_axis . laxis_generate .= autoScaledLogAxis (LogAxisParams show)
    --   else return ()

    -- hint ?
    --layout_x_axis . laxis_generate .= autoIndexAxis (map fst values)



    mapM_ plotIt series

  where
    plotIt (name,xys) = do
      color <- takeColor
      shape <- takeShape

      let (xs,ys) = unzip xys
          xsi     = map fromData xs :: [Int]
          ysd     = map fromData ys :: [Double]
          sorted  = (sortBy (\(x,_) (x',_) -> x `compare` x')  $ zip xsi ysd)

      plot $ myline color name [sorted]
      plot $ mypoints color shape name sorted

    myline :: AlphaColour Double -> String -> [[(x,y)]]  -> EC l (PlotLines x y)
    myline color title values = liftEC $ do
      plot_lines_title .= title
      plot_lines_values .= values
      plot_lines_style . line_color .= color
      plot_lines_style . line_width .= 1


    mypoints :: AlphaColour Double -> PointShape -> String -> [(x,y)] -> EC l (PlotPoints x y)
    mypoints color shape name values = liftEC $ do
      plot_points_values .= values
      plot_points_title .= name
      plot_points_style . point_color .= transparent
      plot_points_style . point_shape .= shape
      plot_points_style . point_border_width .= 1
      plot_points_style . point_border_color .= color
      plot_points_style . point_radius .= 2

plotDoubleDouble :: PlotConfig -> [(Key, [(SeriesDatum, SeriesDatum)])] -> IO ()
plotDoubleDouble = error "hsbencher-graph: plotDoubleDouble not implemented!!"

#endif

---------------------------------------------------------------------------
-- Types in the data

-- |
unifyTypes :: (Key,[LinePoint]) -> (Key,[LinePoint])
unifyTypes (name,series) =
  let (xs,ys,errs) = (map x series, map y series, map err series)
      xs' = unify xs
      ys' = unify ys
  in (name, zipWith3 LinePoint xs' ys' errs)
  where
    isString :: SeriesDatum -> Bool
    isString (StringData _) = True
    isString _ = False

    isInt :: SeriesDatum -> Bool
    isInt (IntData _) = True
    isInt _ = False

    unify xs =
      case (any isString xs, any isInt xs, any isNum xs) of
        (True, _, _)   -> map (StringData . convertToString) xs
        (False,_,True) -> map convertToNum xs
        (False,True,False) -> xs
        (False,False,False) -> error "hsbencher-graph/unifyTypes: value is not a string Int or Double: "++xs
    convertToNum (IntData x) = NumData (fromIntegral x)
    convertToNum (NumData x) = NumData x
    convertToNum (StringData str) = error $ "Attempting to convert string " ++ str ++ " to Num"

-- | Returns the type of the X values and the type of the Y values.
typecheck :: [(Key,[LinePoint])] -> Maybe (ValueType, ValueType)
typecheck dat =
  let series = concatMap snd dat
      (xs,ys) = (map x series, map y series)
  in
   case length xs >= 1 && length ys >= 1 of
     True ->
       let x = seriesType $ head xs
           y = seriesType $ head ys
           _xb = all (==x) $ map seriesType xs
           _yb = all (==y) $ map seriesType ys
       in Just (x,y)
     False -> Nothing

---------------------------------------------------------------------------

-- | Extract the data we care about from in-memory CSV data.
--   This includes a bit of data cleaning for missing values in the X/Y columns.
--
-- Note: This is in the IO monad only to produce chatter.
--
-- Returns: 1. the good data series, extracted line data ZIPPED with the original rows.
--          2. the misfits - bad rows that had Y values but were missing X values.
extractData :: [ColName] -> (ColName,ColName,Maybe ErrorCols)
            -> ValidatedCSV -> IO (DataSeries,DataSeries)
extractData keys (xcol,ycol,errcols) (ValidatedCSV csvhdr rest) =
  case (length keyIxs) == (length keys) of
    False -> error $ "Keys "++ show keys++" were not all found in schema: "++show csvhdr
    True -> do
      (m',aux') <- loop (xcolIx,ycolIx) (M.empty,M.empty) rest
      return (m',aux')
  where
    keyIxs = catMaybes $ zipWith elemIndex keys (replicate (length keys) csvhdr)
    xcolIx = getIx xcol
    ycolIx = getIx ycol
    getIx col =
       case elemIndex col csvhdr of
          Just ix -> ix
          Nothing -> error $ show ycol ++ " is not present in csv."

    loop _  (m,aux) [] = return (m,aux)
    loop xy (m,aux) (row:restRows)= do
      case row of
        -- In the odd event that an empty line occurs:
        []  -> loop xy (m,aux) restRows -- FIXME - this should be part of validation?
        -- A real string, lets see if it contains anything useful:
        _ -> do
          -- split out the csv fields
          let csv = map strip row -- Again, should be part of validation of we want to do it.
              -- Construct a key
              key = toKey keys (ValidatedRow csvhdr row)

              -- Find x,y pairs
              (xStr,yStr)  = collectXY xy csv
          -- empty string at key position.
          -- May be of importance!
          case (xStr,yStr) of
            ("","") -> do chatter$ "has no x/y values: " ++ show key ++ " discarding."
                          loop  xy (m,aux) restRows
            ("",a)  -> do chatter$ "has no x value: " ++ show key ++ " Goes into aux data."
                          let aux' = insertVal aux key (LinePoint{ x= StringData "NO_X_VALUE"
                                                             , y= toSeriesDatum a
                                                             , err=NoError })
                          loop  xy (m,aux') restRows
            (_a,"") -> do chatter$ "has no y value: " ++ show key ++ " discarding."
                          loop  xy (m,aux) restRows
            (x,y)   -> let e = case errcols of
                                 Nothing -> NoError
                                 Just (ErrDelta nm) -> DeltaVal $ readDbl $ collectVal (getIx nm) csv
                                 Just (ErrMinMax mn mx) ->
                                   MinMaxVal (readDbl$ collectVal (getIx mn) csv)
                                             (readDbl$ collectVal (getIx mx) csv)
                           m' = insertVal m key (LinePoint { x= toSeriesDatum x
                                                       , y= toSeriesDatum y
                                                       , err=e
                                                       })
                       in  loop  xy (m',aux) restRows


    collectXY (x,y) csv =  ( collectVal x csv
                           , collectVal y csv)
    -- FIXME: I believe using maps is a lot cleaner
    collectVal ix csv =
      -- trace ("Dereferencing !!2: "++show(csv,ix)) $
      csv !! ix

toSeriesDatum :: String -> SeriesDatum
toSeriesDatum x =
    case recogValueType x of
      Int    -> IntData (read x)
      Double -> NumData (read x)
      String -> StringData x

---------------------------------------------------------------------------
-- Recognize data


-- The rules.
-- The string contains only numerals -> Int
-- The string contains only numerals and exactly one . -> Double
-- the string contains exactly one . and an e -> Double
-- The string contains any non-number char -> String

-- there is an ordering to the rules.
-- # 1 If any element of the
--     input contains something that implies String. They are all interpreted as Strings
-- # 2 If not #1 and any element contains . or . and e All values are doubles
-- # 3 If not #1 and #2 treat as Int

-- May be useless. just treat all values as "Double"

-- | Figure out what type of value is stored in this data series.
recogValueType :: String -> ValueType
recogValueType str =
  case (isString str, isInt str, isDouble str) of
    (True,_,_)           -> String
    (False,True, False)  -> Int
    (False,_, True)      -> Double
    (_, _, _)            -> String
  where
    isInt s = all isNumber s
    -- Not a very proper check.
    isDouble s = ((all isNumber $ delete '.' s)
                    || (all isNumber $ delete '.' $ delete 'e' s)
                    || (all isNumber $ delete '.' $ delete 'e' $ delete '-' s))
                   && '.' `elem` s
    isString s = not (isInt s) && not (isDouble s)



---------------------------------------------------------------------------
-- get a value to normalise against
---------------------------------------------------------------------------

-- | Simply do a lookup in EITHER map, left-biased.
getBaseVal :: (Show k,Ord k) => k -> M.Map k a -> M.Map k a -> a
getBaseVal normKey csv aux =
  case (M.lookup normKey csv, M.lookup normKey aux) of
    (Nothing, Nothing) -> error $ "Value to normalise against not found: "++show normKey ++
                                  "\nAll keys: "++show (M.keys csv)
    (Just v,_) -> v
    (_,Just v) -> v

type MultilineDataset = [(Key,[LinePoint])]

-- | Simpler than normalise, this just operates pointwise on the data.
mapPoints :: (Key -> LinePoint -> LinePoint) -> MultilineDataset -> MultilineDataset
mapPoints _ [] = []
mapPoints f ((k,lps):xs) = (k, L.map (f k)  lps) : mapPoints f xs

-- | Find the normalization value that matches a given line
-- represented by Key. Takes the Y-column name (as well as key) which
-- it uses to extract and return the Y value form the selected
-- normalization point.
-- 
-- This assumes that all the points on a given
-- line use the same normalization factor, rather than something
-- dynamic that depends on the X axis.
findNorm :: (Key,ColName) -> NormValueSpec -> ValidatedCSV -> SeriesDatum
findNorm (key, ycol) nvs0 vcsv0 =
    case toRows (filterWithSpec (toRowFilter key nvs0) vcsv0) of
      [row] -> toSeriesDatum (row #! ycol)
      [] -> error $ "findNorm: no row found matching spec!: "++ show nvs0
      ls -> error ("findNorm not enough information in spec: "++show nvs0++
                   "\nDid not filter down to a single row for the normalization value.\n"++
                   "Instead it left "++show (length ls)++" rows:\n "++show ls)

-- | A predicate on rows.
type RowFilter = ValidatedRow -> Bool

type Constraint = (ColName,String)

-- | Use the filters implied by a NormValueSpec to create a predicate
--   on rows of a CSV.  Requires a designated Key, because
--   NormValueSpec's are relative to an /observer/.  Filters mentioned
--   in the NormValueSpec which don't have a concrete value (RHS),
--   implicitly filter to use the same value as the current key.
toRowFilter :: Key -> NormValueSpec -> RowFilter 
toRowFilter key (NormValueSpec nls) row =
    go nls
  where
    go [] = True
    go ((col,Nothing):rest) = (keyLookup col key) == (row #! col) && go rest
    go ((col,Just v):rest)  = v == (row #! col) && go rest


-- | Filter the rows of a CSV dataset.
filterWithSpec :: RowFilter -> ValidatedCSV -> ValidatedCSV
filterWithSpec _ v@(ValidatedCSV _ []) = v
filterWithSpec fn (ValidatedCSV hdr (row:rest)) =
   let ValidatedCSV _ rest' = filterWithSpec fn (ValidatedCSV hdr rest) in
   if fn (ValidatedRow hdr row)
   then ValidatedCSV hdr (row:rest')
   else ValidatedCSV hdr rest'




-- | Normalize a set of lines against their respective normalization values.
--   This requires equal-length, isomorphic data series.
normalise :: [LinePoint] -> MultilineDataset -> MultilineDataset
normalise []   _  = error "No Value to normalise against"
normalise base0 lns
  = [ (nom, fragileZipWith doIt base0 series) | (nom,series) <- lns ]
  where

    doIt :: LinePoint -> LinePoint -> LinePoint
    doIt (p1@(LinePoint{x, y=NumData normY}))
          p2@(LinePoint {x=sx, y= NumData sy, err}) =
      if x==sx
      then LinePoint {x=sx, y=NumData (sy / normY), err }
           -- Report the ratio of the line to the norm line.
      else error $ "hsbencher-graph/normalise: mismatched X data points in line and normalisation baseline:\n    "
                   ++ show p1 ++ "\n vs: "++show p2
    doIt p1 p2 =
        error $ "hsbencher-graph/normalise: mismatched Y data points in line and normalisation baseline:\n    "
                  ++ show p1 ++ "\n vs: "++show p2
    -- doIt [] p2 =
    --     error $ "hsbencher-graph/normalise: mismatched data points and normalisation baseline.\n"
    --             ++ "Baseline ran out to soon.  Points remaining"
    --              ++ show p2

replace :: Eq a => [a] -> [a] -> [a] -> [a]
replace old new = intercalate new . splitOn old

-- | A list of "OLD,NEW" mappings.
type RenameTable = [String]

-- | A renamer operates on the printed representation of the key.
buildRenamer :: RenameTable -> Key -> String
buildRenamer [] = show

-- Empty lines are ignored:
buildRenamer (ln:rest) =
  case words ln of
    []    -> buildRenamer rest
    (a:_) | "#" `L.isPrefixOf` a -> buildRenamer rest -- Allow comment lines.
    _ -> 
     case (splitOn "," ln) of
       [lhs,rhs] -> \ key ->
                    trace ("Renaming "++show (lhs,rhs)++" in "++show key)$
                    replace lhs rhs $
                    buildRenamer rest key
       _ -> error ("Bad line in rename table: "++ ln)

fromValidated :: ValidatedCSV -> CSV.CSV
fromValidated ValidatedCSV{header,rows} = header : rows


-- TODO: Change this to use ValidatedRow / RowFilter
-- | Take pre-validated CSV and apply filters to CSV data.
doFilters :: [Flag] -> ValidatedCSV -> ValidatedCSV
doFilters [] dat = dat
doFilters (FilterEq col vals : rest) (ValidatedCSV header csv) =
   doFilters rest $ ValidatedCSV header $
     filter ((\x -> any (==x) vals) . mkPrj header col) csv
doFilters (FilterContain col vals : rest) (ValidatedCSV header csv) =
   doFilters rest $ ValidatedCSV header $
     filter ((\x -> any (`isInfixOf` x) vals) . mkPrj header col) csv

doFilters (FilterRange col minV maxV : rest) (ValidatedCSV header csv) =
   doFilters rest $ ValidatedCSV header $
     filter ((\x -> read x >= minV && read x <= maxV) . mkPrj header col) csv

-- | Everything else we ignore:
doFilters (_ : rest) dat = doFilters rest dat

                           
                           
-- | Build a projection function that looks up a given key.
mkPrj :: (Show b, Eq b) => [b] -> b -> [a] -> a
mkPrj header col =
  case elemIndex col header of
    Just ix -> \row ->
      -- trace ("Dereferencing: !!0"++show(row,ix)) $
      row !! ix
    Nothing -> error $ show col ++ " is not present in csv."


doPadding :: [(String,Int)] -> ValidatedCSV -> ValidatedCSV
doPadding ls (ValidatedCSV header csv) =
   ValidatedCSV header $ loop ls csv
  where
   loop [] rows = rows
   loop ((col,pad):rest) rows = map (mkPadder col pad) $
                                loop rest rows
   mkPadder :: ColName -> Int -> CSV.Record -> CSV.Record
   mkPadder col padto =
     let padit s =
           -- Make sure it is a number we are padding
          case reads s of
             [(n,"")] -> let s' = show (n::Integer)
                         in replicate (padto - length s') '0' ++ s'
             _ -> error $ "attempting to --pad something not an integer: "++s

           in
     case elemIndex col header of
       Just ix -> \row ->
         let row' = take (ix) row ++ [padit (row !! ix)] ++ drop (ix+1) row
         in -- trace ("PADDING ROW "++col++" at index "++ show ix++": "++show row')
            row'
       Nothing -> error $ show col ++ " is not present in csv."

-- | Resolve groups of rows that share the same key
takeLatest :: [ColName] -> ColName -> ValidatedCSV -> ValidatedCSV
takeLatest keys col dat =
  let keyed = toKeyedGroups keys dat
      hdr   = header dat
      mp'   = M.map (\ls -> reverse $ rows $
                            sortCSVBy col compareStrDoubles (ValidatedCSV hdr ls))
                    (krows keyed)
      remaining = L.map head (M.elems mp')
  in ValidatedCSV hdr remaining

-- | Comparison on Strings that are actually valid Doubles.
compareStrDoubles :: String -> String -> Ordering
compareStrDoubles a b =
  case (reads a,reads b) of
    ((n,_):_,(m,_):_) -> compare (n::Double) m
    _ -> error $ "compareStrDoubles: expected both of these to parse as Double: "++ show (a,b)

-- | Sort the rows by a certain column.
sortCSVBy :: ColName -> (String -> String -> Ordering) -> ValidatedCSV -> ValidatedCSV
sortCSVBy col fn ValidatedCSV{header,rows} = ValidatedCSV header rows'
-- This does seem to get into needless reimplementation of DB functionality...
 where
  rows' = L.sortBy fn' rows
  fn' a b = fn (prj a) (prj b)
  prj = mkPrj header col

toKeyedGroups :: [ColName] -> ValidatedCSV -> KeyedCSV
toKeyedGroups keys ValidatedCSV{header,rows} =
  case (length keyIxs) == (length keys) of
    False -> error $ "Keys "++ show keys++" were not all found in schema: "++show header
    True -> KeyedCSV keys header (loop M.empty rows)
 where
  keyIxs = catMaybes $ zipWith elemIndex keys (replicate (length keys) header)
  loop !mp [] = mp
  loop !mp (row:rest) =
    let mp' = M.insertWith' (++) (toKey keys (ValidatedRow header row)) [row] mp in
    loop mp' rest

         
        

-- | Collapse keyed groups back down to a flat list of rows, in no
-- particular order.
fromKeyedGroups :: KeyedCSV -> ValidatedCSV
fromKeyedGroups KeyedCSV{kheader,krows} =
  ValidatedCSV kheader (M.fold (++) [] krows)

-- | Make sure that each row has the right number of columns ad discard blank lines.
--   Remove any whitespace around header column names.
--
--   If the ValidatedCSV constructor is stripped off and this is
--   reapplied, then this function must be idempotent.
validateCSV :: CSV.CSV -> ValidatedCSV
validateCSV [] = error "validateCSV: empty CSV data (no header row)"
validateCSV (header:csv) = ValidatedCSV (map strip header) (loop (2::Int) csv)
  where
   numCols = length header -- TODO: could validate that column names look
                           -- right, i.e. probably shouldn't be numbers!
   loop _ [] = []
   loop p ([]:rest) = loop (p+1) rest -- Discard blank
   -- Ok, this is kind of weird... Text.CSV parses a trailing blank line
   -- as having one field of zero size:
   loop p ([""]:rest) = loop (p+1) rest
   loop pos (row:rest)
     | length row == numCols = row : loop (pos+1) rest
     | otherwise = error $ "error in validateCSV: encountered on row #"++ show pos
                   ++ "\nRow did not contain the expected number of columns: "++show numCols
                   ++"\nCSV schema was:\n  "++show header
                   ++"\nOffending row (length "++show (length row)++") was:\n  "++show row

-- | Summarize each column
printSummary :: ValidatedCSV -> IO ()
printSummary ValidatedCSV{header,rows} = do
  chatter "Printing summary of each column:"
  hPutStrLn stderr "   --------------------------------------------------------------------------------"
  forM_ rotated $ \ (hdr:vals) -> do
     let uniques = S.toAscList $ S.fromList vals
     hPutStrLn stderr $ "   "++hdr++": "++ summarize 300 (show uniques)
  hPutStrLn stderr "   --------------------------------------------------------------------------------\n"
  where
    rotated = L.transpose (header:rows)


summarize :: Int -> String -> String
summarize limit str =
  case L.splitAt limit str of
    (hd,[]) -> hd
    (hd,_)  -> hd ++ "..."


fst3 :: (t, t1, t2) -> t
fst3 (a,_,_) = a


readDbl :: String -> Double
readDbl s =
  case reads s of
    (d,_):_ -> d
    _ -> error $ "Could not parse string as a Double: "++s

readInt :: String -> Int
readInt s =
  case reads s of
    (x,_):_ -> x
    _ -> error $ "Could not parse string as an Int: "++s

(#!) :: ValidatedRow -> ColName -> String
(ValidatedRow hdr row) #! col =
    mkPrj hdr col row

(#) :: (Ord k,Show k) => M.Map k v -> k -> v
m # k = case M.lookup k m of
          Just x -> x
          Nothing -> error $ "Map did not contain key: "++show k
                          ++ "\nAll keys: "++show (M.keys m)

fragileZipWith :: (Show a, Show b) => (a -> b -> c) -> [a] -> [b] -> [c]
fragileZipWith fn l1 l2 = go l1 l2
 where
   go [] [] = []
   go (a:as) (b:bs) = fn a b : go as bs
   go [] bs = error $ "fragileZipWith: left list ran out first.  Remaining:\n "
                ++take 500 (show bs)
   go as [] = error $ "fragileZipWith: right list ran out first.  Remaining:\n "
                ++take 500 (show as)

